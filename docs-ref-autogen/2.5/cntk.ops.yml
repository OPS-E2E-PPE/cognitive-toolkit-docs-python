### YamlMime:UniversalReference
api_name: []
items:
- children:
  - cntk.ops.abs
  - cntk.ops.acos
  - cntk.ops.alias
  - cntk.ops.argmax
  - cntk.ops.argmin
  - cntk.ops.as_block
  - cntk.ops.as_composite
  - cntk.ops.asin
  - cntk.ops.asinh
  - cntk.ops.assign
  - cntk.ops.associative_multi_arg
  - cntk.ops.atanh
  - cntk.ops.batch_normalization
  - cntk.ops.cast
  - cntk.ops.ceil
  - cntk.ops.clip
  - cntk.ops.combine
  - cntk.ops.constant
  - cntk.ops.convolution
  - cntk.ops.convolution_transpose
  - cntk.ops.cos
  - cntk.ops.cosh
  - cntk.ops.crop_automatic
  - cntk.ops.crop_automatic_with_ancestors
  - cntk.ops.crop_manual
  - cntk.ops.depth_to_space
  - cntk.ops.dropout
  - cntk.ops.element_and
  - cntk.ops.element_divide
  - cntk.ops.element_max
  - cntk.ops.element_min
  - cntk.ops.element_not
  - cntk.ops.element_or
  - cntk.ops.element_select
  - cntk.ops.element_times
  - cntk.ops.element_xor
  - cntk.ops.elu
  - cntk.ops.equal
  - cntk.ops.exp
  - cntk.ops.expand_dims
  - cntk.ops.flatten
  - cntk.ops.floor
  - cntk.ops.forward_backward
  - cntk.ops.gather
  - cntk.ops.greater
  - cntk.ops.greater_equal
  - cntk.ops.hard_sigmoid
  - cntk.ops.hardmax
  - cntk.ops.image_scaler
  - cntk.ops.input
  - cntk.ops.input_variable
  - cntk.ops.labels_to_graph
  - cntk.ops.leaky_relu
  - cntk.ops.less
  - cntk.ops.less_equal
  - cntk.ops.local_response_normalization
  - cntk.ops.log
  - cntk.ops.log_add_exp
  - cntk.ops.log_softmax
  - cntk.ops.mean
  - cntk.ops.mean_variance_normalization
  - cntk.ops.minus
  - cntk.ops.negate
  - cntk.ops.not_equal
  - cntk.ops.one_hot
  - cntk.ops.ones_like
  - cntk.ops.optimized_rnnstack
  - cntk.ops.output_variable
  - cntk.ops.pad
  - cntk.ops.param_relu
  - cntk.ops.parameter
  - cntk.ops.per_dim_mean_variance_normalize
  - cntk.ops.placeholder
  - cntk.ops.plus
  - cntk.ops.pooling
  - cntk.ops.pow
  - cntk.ops.random_sample
  - cntk.ops.random_sample_inclusion_frequency
  - cntk.ops.reciprocal
  - cntk.ops.reconcile_dynamic_axes
  - cntk.ops.reduce_l1
  - cntk.ops.reduce_l2
  - cntk.ops.reduce_log_sum_exp
  - cntk.ops.reduce_max
  - cntk.ops.reduce_mean
  - cntk.ops.reduce_min
  - cntk.ops.reduce_prod
  - cntk.ops.reduce_sum
  - cntk.ops.reduce_sum_square
  - cntk.ops.relu
  - cntk.ops.reshape
  - cntk.ops.roipooling
  - cntk.ops.round
  - cntk.ops.selu
  - cntk.ops.sigmoid
  - cntk.ops.sin
  - cntk.ops.sinh
  - cntk.ops.slice
  - cntk.ops.softmax
  - cntk.ops.softplus
  - cntk.ops.softsign
  - cntk.ops.space_to_depth
  - cntk.ops.splice
  - cntk.ops.sqrt
  - cntk.ops.square
  - cntk.ops.squeeze
  - cntk.ops.stop_gradient
  - cntk.ops.sum
  - cntk.ops.swapaxes
  - cntk.ops.tanh
  - cntk.ops.times
  - cntk.ops.times_transpose
  - cntk.ops.to_batch
  - cntk.ops.to_sequence
  - cntk.ops.to_sequence_like
  - cntk.ops.top_k
  - cntk.ops.transpose
  - cntk.ops.unpack_batch
  - cntk.ops.unpooling
  - cntk.ops.zeros_like
  - cntk.ops.functions
  - cntk.ops.sequence
  fullName: cntk.ops
  langs:
  - python
  module: cntk.ops
  name: ops
  source:
    id: ops
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 0
  summary: 'CNTK core operators. Calling these operators creates nodes in the CNTK
    computational graph.

    '
  type: package
  uid: cntk.ops
- example:
  - '

    ```


    >>> C.abs([-1, 1, -2, 3]).eval()

    array([ 1.,  1.,  2.,  3.], dtype=float32)

    ```

    '
  fullName: cntk.ops.abs
  langs:
  - python
  module: cntk.ops
  name: abs
  source:
    id: abs
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1988
  summary: 'Computes the element-wise absolute of `x`:


    '
  syntax:
    content: abs(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.abs
- example:
  - "\n```\n\n>>> np.round(C.acos([[1,0.5],[-0.25,-0.75]]).eval(),5)\narray([[ 0.\
    \     ,  1.0472 ],\n       [ 1.82348,  2.41886]], dtype=float32)\n```\n"
  fullName: cntk.ops.acos
  langs:
  - python
  module: cntk.ops
  name: acos
  source:
    id: acos
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1637
  summary: 'Computes the element-wise arccos (inverse cosine) of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: acos(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.acos
- fullName: cntk.ops.alias
  langs:
  - python
  module: cntk.ops
  name: alias
  source:
    id: alias
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 197
  summary: "   Create a new Function instance which just aliases the specified 'x'\
    \ Function/Variable\n   such that the 'Output' of the new 'Function' is same as\
    \ the 'Output' of the specified\n   'x' Function/Variable, and has the newly specified\
    \ name.\n   The purpose of this operator is to create a new distinct reference\
    \ to a symbolic\n   computation which is different from the original Function/Variable\
    \ that it aliases and can\n   be used for e.g. to substitute a specific instance\
    \ of the aliased Function/Variable in the\n   computation graph instead of substituting\
    \ all usages of the aliased Function/Variable.\n"
  syntax:
    content: alias(x, name='')
    parameters:
    - description: 'The Function/Variable to alias

        '
      id: operand
    - description: 'the name of the Alias Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.alias
- example:
  - "\n```\n\n>>> # create 3x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = [[10, 20],[30, 40],[50, 60]]\n```\n\n\n```\n\n>>> C.argmax(data,\
    \ 0).eval()\narray([[ 2.,  2.]], dtype=float32)\n```\n\n\n```\n\n>>> C.argmax(data,\
    \ 1).eval()\narray([[ 1.],\n       [ 1.],\n       [ 1.]], dtype=float32)\n```\n"
  fullName: cntk.ops.argmax
  langs:
  - python
  module: cntk.ops
  name: argmax
  source:
    id: argmax
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3156
  summary: 'Computes the argmax of the input tensor''s elements across the specified
    axis.

    If no axis is specified, it will return the flatten index of the largest element

    in tensor x.

    '
  syntax:
    content: argmax(x, axis=None, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.argmax
- example:
  - "\n```\n\n>>> # create 3x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = [[10, 30],[40, 20],[60, 50]]\n```\n\n\n```\n\n>>> C.argmin(data,\
    \ 0).eval()\narray([[ 0.,  1.]], dtype=float32)\n```\n\n\n```\n\n>>> C.argmin(data,\
    \ 1).eval()\narray([[ 0.],\n       [ 1.],\n       [ 1.]], dtype=float32)\n```\n"
  fullName: cntk.ops.argmin
  langs:
  - python
  module: cntk.ops
  name: argmin
  source:
    id: argmin
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3189
  summary: 'Computes the argmin of the input tensor''s elements across the specified
    axis.

    If no axis is specified, it will return the flatten index of the smallest element

    in tensor x.

    '
  syntax:
    content: argmin(x, axis=None, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.argmin
- fullName: cntk.ops.as_block
  langs:
  - python
  module: cntk.ops
  name: as_block
  source:
    id: as_block
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 154
  summary: "   Create a new block Function instance which just encapsulates the specified\
    \ composite Function\n   to create a new Function that appears to be a primitive.\
    \ All the arguments of the composite\n   being encapsulated must be Placeholder\
    \ variables.\n   The purpose of block Functions is to enable creation of hierarchical\
    \ Function graphs\n   where details of implementing certain building block operations\
    \ can be encapsulated away\n   such that the actual structure of the block's implementation\
    \ is not inlined into\n   the parent graph where the block is used, and instead\
    \ the block just appears as an opaque\n   primitive. Users still have the ability\
    \ to peek at the underlying Function graph that implements\n   the actual block\
    \ Function.\n"
  syntax:
    content: as_block(composite, block_arguments_map, block_op_name, block_instance_name='')
    parameters:
    - description: 'The composite Function that the block encapsulates

        '
      id: composite
    - description: 'A list of tuples, mapping from block''s underlying composite''s
        arguments to

        actual variables they are connected to

        '
      id: block_arguments_map
    - description: 'Name of the op that the block represents

        '
      id: block_op_name
    - description: 'the name of the block Function in the network

        '
      id: block_instance_name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.as_block
- fullName: cntk.ops.as_composite
  langs:
  - python
  module: cntk.ops
  name: as_composite
  source:
    id: as_composite
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 180
  summary: "   Creates a composite Function that has the specified root_function as\
    \ its root.\n   The composite denotes a higher-level Function encapsulating the\
    \ entire graph\n   of Functions underlying the specified rootFunction.\n"
  syntax:
    content: as_composite(root_function, name='')
    parameters:
    - description: 'Root Function, the graph underlying which, the newly created composite
        encapsulates

        '
      id: root_function
    - description: 'the name of the Alias Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.as_composite
- example:
  - "\n```\n\n>>> np.round(C.asin([[1,0.5],[-0.25,-0.75]]).eval(),5)\narray([[ 1.5708\
    \ ,  0.5236 ],\n       [-0.25268, -0.84806]], dtype=float32)\n```\n"
  fullName: cntk.ops.asin
  langs:
  - python
  module: cntk.ops
  name: asin
  source:
    id: asin
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1659
  summary: 'Computes the element-wise arcsin (inverse sine) of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: asin(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.asin
- example:
  - "\n```\n\n>>> np.round(C.asinh([[1,0.5],[-0.25,-0.75]]).eval(),5)\narray([[ 0.88137,\
    \  0.48121],\n       [-0.24747, -0.69315]], dtype=float32)\n```\n"
  fullName: cntk.ops.asinh
  langs:
  - python
  module: cntk.ops
  name: asinh
  source:
    id: asinh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1725
  summary: 'Computes the element-wise asinh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: asinh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.asinh
- example:
  - "\n```\n\n>>> dest = C.constant(shape=(3,4))\n>>> data = C.parameter(shape=(3,4),\
    \ init=2)\n>>> C.assign(dest,data).eval()\narray([[ 2.,  2.,  2.,  2.],\n    \
    \   [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.]], dtype=float32)\n>>> dest.asarray()\n\
    array([[ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,\
    \  2.,  2.]], dtype=float32)\n```\n\n\n```\n\n>>> dest = C.parameter(shape=(3,4),\
    \ init=0)\n>>> a = C.assign(dest, data)\n>>> y = dest + data\n>>> result = C.combine([y,\
    \ a]).eval()\n>>> result[y.output]\narray([[ 2.,  2.,  2.,  2.],\n       [ 2.,\
    \  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.]], dtype=float32)\n>>> dest.asarray()\n\
    array([[ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,\
    \  2.,  2.]], dtype=float32)\n>>> result = C.combine([y, a]).eval()\n>>> result[y.output]\n\
    array([[ 4.,  4.,  4.,  4.],\n       [ 4.,  4.,  4.,  4.],\n       [ 4.,  4.,\
    \  4.,  4.]], dtype=float32)\n>>> dest.asarray()\narray([[ 2.,  2.,  2.,  2.],\n\
    \       [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.assign
  langs:
  - python
  module: cntk.ops
  name: assign
  source:
    id: assign
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3668
  summary: 'Assign the value in input to ref and return the new value, ref need to
    be the same layout as input.

    Both ref and input can''t have dynamic axis and broadcast isn''t supported for
    the assign operator.

    During forward pass, ref will get the new value after the forward or backward
    pass finish, so that

    any part of the graph that depend on ref will get the old value. To get the new
    value, use the one

    returned by the assign node. The reason for that is to make `assign` have a deterministic
    behavior.


    If not computing gradients, the ref will be assigned the new value after the forward
    pass over the

    entire Function graph is complete; i.e. all uses of ref in the forward pass will
    use the original

    (pre-assignment) value of ref.


    If computing gradients (training mode), the assignment to ref will happen after
    completing both

    the forward and backward passes over the entire Function graph.


    The ref must be a Parameter or Constant. If the same ref is used in multiple assign
    operations,

    then the order in which the assignment happens is non-deterministic and the final
    value can be

    either of the assignments unless an order is established using a data dependence
    between the

    assignments.

    '
  syntax:
    content: assign(ref, input, name='')
    parameters:
    - description: 'class: *~cntk.variables.Constant* or *~cntk.variables.Parameter*.

        '
      id: ref
    - description: 'class:*~cntk.ops.functions.Function* that outputs a tensor

        '
      id: input
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.assign
- example:
  - '

    ```


    >>> C.plus([1, 2, 3], [4, 5, 6]).eval()

    array([ 5.,  7.,  9.], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.]).eval()

    array([ 10.,  20.,  30.,  60.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10], [3, 2, 3, 2, 3], [-13], [+42], ''multi_arg_example'').eval()

    array([ 37.,  37.,  39.,  39.,  41.], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.], [1., 2., 1., 2.]).eval()

    array([  10.,   40.,   30.,  120.], dtype=float32)

    ```



    ```


    >>> a = np.arange(3,dtype=np.float32)

    >>> np.exp(C.log_add_exp(np.log(1+a), np.log(1+a*a)).eval())

    array([ 2.,  4.,  8.], dtype=float32)

    ```

    '
  fullName: cntk.ops.associative_multi_arg
  langs:
  - python
  module: cntk.ops
  name: associative_multi_arg
  source:
    id: associative_multi_arg
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 784
  summary: 'The output of this operation is the result of an operation (*plus*, *log_add_exp*,
    *element_times*, *element_max*, *element_min*)

    of two or more input tensors. Broadcasting is supported.

    '
  syntax:
    content: associative_multi_arg(f)
    parameters:
    - description: 'left side tensor

        '
      id: left
    - &id001
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id001
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.associative_multi_arg
- example:
  - "\n```\n\n>>> np.round(C.atanh([[0.9,0.5],[-0.25,-0.75]]).eval(),5)\narray([[\
    \ 1.47222,  0.54931],\n       [-0.25541, -0.97296]], dtype=float32)\n```\n"
  fullName: cntk.ops.atanh
  langs:
  - python
  module: cntk.ops
  name: atanh
  source:
    id: atanh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1571
  summary: 'Computes the element-wise atanh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: atanh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.atanh
- fullName: cntk.ops.batch_normalization
  langs:
  - python
  module: cntk.ops
  name: batch_normalization
  source:
    id: batch_normalization
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 544
  summary: 'Normalizes layer outputs for every minibatch for each output (feature)
    independently

    and applies affine transformation to preserve representation of the layer.

    '
  syntax:
    content: batch_normalization(operand, scale, bias, running_mean, running_inv_std,
      spatial, normalization_time_constant=5000, blend_time_constant=0, epsilon=1e-05,
      use_cudnn_engine=False, disable_regularization=False, name='', running_count=None)
    parameters:
    - description: 'input of the batch normalization operation

        '
      id: operand
    - description: 'parameter tensor that holds the learned componentwise-scaling
        factors

        '
      id: scale
    - description: 'parameter tensor that holds the learned bias. `scale` and `bias`
        must have the same

        dimensions which must be equal to the input dimensions in case of `spatial`
        = False or

        number of output convolution feature maps in case of `spatial` = True

        '
      id: bias
    - description: 'running mean which is used during evaluation phase and might be
        used during

        training as well. You must pass a constant tensor with initial value 0 and
        the same dimensions

        as `scale` and `bias`

        '
      id: running_mean
    - description: 'running variance. Represented as `running_mean`

        '
      id: running_inv_std
    - description: 'Denotes the total number of samples that have been used so far
        to compute

        the `running_mean` and `running_inv_std` parameters. You must pass a scalar
        (either rank-0 `constant(val)`).

        '
      id: running_count
    - description: 'flag that indicates whether to compute mean/var for each feature
        in a minibatch

        independently or, in case of convolutional layers, per future map

        '
      id: spatial
      type:
      - bool
    - description: 'time constant for computing running average of

        mean and variance as a low-pass filtered version of the batch statistics.

        '
      id: normalization_time_constant
      type:
      - float, default 5000
    - description: 'constant for smoothing batch estimates with the running

        statistics

        '
      id: blend_time_constant
      type:
      - float, default 0
    - description: 'conditioner constant added to the variance when computing the
        inverse standard deviation

        '
      id: epsilon
    - description: ''
      id: use_cudnn_engine
      type:
      - bool, default True
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - description: 'turn off regularization in batch normalization

        '
      id: disable_regularization
      type:
      - bool, default False
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.batch_normalization
- fullName: cntk.ops.cast
  langs:
  - python
  module: cntk.ops
  name: cast
  source:
    id: cast
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3900
  summary: 'cast input to dtype, with the same shape and dynamic axes. This function
    currently only support forward.

    '
  syntax:
    content: cast(node_input, dtype, name='')
    parameters:
    - description: 'class:*~cntk.input_variable* that needs the dtype conversion

        '
      id: node_input
    - description: 'data_type (np.float32, np.float64, np.float16): data type of the
        converted output

        '
      id: dtype
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.cast
- example:
  - "\n```\n\n>>> C.ceil([0.2, 1.3, 4., 5.5, 0.0]).eval()\narray([ 1.,  2.,  4., \
    \ 6.,  0.], dtype=float32)\n```\n\n\n```\n\n>>> C.ceil([[0.6, 3.3], [1.9, 5.6]]).eval()\n\
    array([[ 1.,  4.],\n       [ 2.,  6.]], dtype=float32)\n```\n"
  fullName: cntk.ops.ceil
  langs:
  - python
  module: cntk.ops
  name: ceil
  source:
    id: ceil
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1245
  summary: 'The output of this operation is the element wise value rounded to the
    smallest

    integer greater than or equal to the input.

    '
  syntax:
    content: ceil(arg, name='')
    parameters:
    - description: 'input tensor

        '
      id: arg
    - description: 'the name of the Function instance in the network (optional)

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.ceil
- example:
  - '

    ```


    >>> C.clip([1., 2.1, 3.0, 4.1], 2., 4.).eval()

    array([ 2. ,  2.1,  3. ,  4. ], dtype=float32)

    ```



    ```


    >>> C.clip([-10., -5., 0., 5., 10.], [-5., -4., 0., 3., 5.], [5., 4., 1., 4.,
    9.]).eval()

    array([-5., -4.,  0.,  4.,  9.], dtype=float32)

    ```

    '
  fullName: cntk.ops.clip
  langs:
  - python
  module: cntk.ops
  name: clip
  source:
    id: clip
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1309
  summary: 'Computes a tensor with all of its values clipped to fall

    between `min_value` and `max_value`, i.e.

    `min(max(x, min_value), max_value)`.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: clip(x, min_value, max_value, name='')
    parameters:
    - description: 'tensor to be clipped

        '
      id: x
    - description: 'a scalar or a tensor which represents the minimum value to clip
        element

        values to

        '
      id: min_value
      type:
      - float
    - description: 'a scalar or a tensor which represents the maximum value to clip
        element

        values to

        '
      id: max_value
      type:
      - float
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.clip
- example:
  - "\n```\n\n>>> in1 = C.input_variable((4,))\n>>> in2 = C.input_variable((4,))\n\
    ```\n\n\n```\n\n>>> in1_data = np.asarray([[1., 2., 3., 4.]], np.float32)\n>>>\
    \ in2_data = np.asarray([[0., 5., -3., 2.]], np.float32)\n```\n\n\n```\n\n>>>\
    \ plus_operation = in1 + in2\n>>> minus_operation = in1 - in2\n```\n\n\n```\n\n\
    >>> forward = C.combine([plus_operation, minus_operation]).eval({in1: in1_data,\
    \ in2: in2_data})\n>>> len(forward)\n2\n>>> list(forward.values()) # doctest:\
    \ +SKIP\n[array([[[ 1., -3.,  6.,  2.]]], dtype=float32),\n array([[[ 1.,  7.,\
    \  0.,  6.]]], dtype=float32)]\n>>> x = C.input_variable((4,))\n>>> _ = C.combine(x,\
    \ x)\n>>> _ = C.combine([x, x])\n>>> _ = C.combine((x, x))\n>>> _ = C.combine(C.combine(x,\
    \ x), x)\n```\n"
  fullName: cntk.ops.combine
  langs:
  - python
  module: cntk.ops
  name: combine
  source:
    id: combine
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 30
  summary: "   Create a new Function instance which just combines the outputs of the\
    \ specified list of\n   'operands' Functions such that the 'Outputs' of the new\
    \ 'Function' are union of the\n   'Outputs' of each of the specified 'operands'\
    \ Functions. E.g., when creating a classification\n   model, typically the CrossEntropy\
    \ loss Function and the ClassificationError Function comprise\n   the two roots\
    \ of the computation graph which can be combined to create a single Function\n\
    \   with 2 outputs; viz. CrossEntropy loss and ClassificationError output.\n"
  syntax:
    content: combine(*operands, **kw_name)
    parameters:
    - description: 'list of functions or their variables to combine

        '
      id: operands
      type:
      - list
    - description: 'the name of the Combine Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.combine
- example:
  - "\n```\n\n>>> constant_data = C.constant([[1., 2.], [3., 4.], [5., 6.]])\n>>>\
    \ constant_data.value\narray([[ 1.,  2.],\n       [ 3.,  4.],\n       [ 5.,  6.]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.constant
  langs:
  - python
  module: cntk.ops
  name: constant
  source:
    id: constant
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3599
  summary: 'It creates a constant tensor initialized from a numpy array.

    '
  syntax:
    content: constant(value=None, shape=None, dtype=None, device=None, name='')
    parameters:
    - description: 'a scalar initial value that would be replicated for

        every element in the tensor or NumPy array.

        If `None`, the tensor will be initialized uniformly random.

        '
      id: value
      type:
      - scalar
      - NumPy array, optional
    - description: 'the shape of the input tensor. If not provided, it will

        be inferred from `value`.

        '
      id: shape
      type:
      - tuple
      - int, optional
    - description: 'data type of the constant. If a NumPy array and `dtype`,

        are given, then data will be converted if needed. If none given, it will default
        to `np.float32`.

        '
      id: dtype
      type:
      - optional
    - description: 'instance of DeviceDescriptor

        '
      id: device
      type:
      - cntk.device.DeviceDescriptor
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Constant

        '
  type: function
  uid: cntk.ops.constant
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(25.0, dtype = np.float32), (1, 5, 5))\n\
    >>> x = C.input_variable(img.shape)\n>>> filter = np.reshape(np.array([2, -1,\
    \ -1, 2], dtype = np.float32), (1, 2, 2))\n>>> kernel = C.constant(value = filter)\n\
    >>> np.round(C.convolution(kernel, x, auto_padding = [False]).eval({x: [img]}),5)\n\
    array([[[[  6.,   8.,  10.,  12.],\n          [ 16.,  18.,  20.,  22.],\n    \
    \      [ 26.,  28.,  30.,  32.],\n          [ 36.,  38.,  40.,  42.]]]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.convolution
  langs:
  - python
  module: cntk.ops
  name: convolution
  source:
    id: convolution
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 291
  summary: "Computes the convolution of `convolution_map` (typically a tensor of learnable\
    \ parameters) with\n`operand` (commonly an image or output of a previous convolution/pooling\
    \ operation).\nThis operation is used in image and language processing applications.\
    \ It supports arbitrary\ndimensions, strides, sharing, and padding.\n\nThis function\
    \ operates on input tensors with dimensions . This can be understood as a rank-n\n\
    object, where each entry consists of a -dimensional vector. For example, an RGB\
    \ image would have dimensions\n, i.e. a -sized structure, where each entry (pixel)\
    \ consists of a 3-tuple.\n\n*convolution* convolves the input `operand` with a\
    \  rank tensor of (typically learnable) filters called\n`convolution_map` of shape\
    \  (typically ).\nThe first dimension, , is the nunber of convolution filters\
    \ (i.e. the number of\nchannels in the output). The second dimension, , must match\
    \ the number of channels in the input, which can be ignored if *reduction_rank*\
    \ is *0*.\nThe last n dimensions are the spatial extent of the filter. I.e. for\
    \ each output position, a vector of\ndimension  is computed. Hence, the total\
    \ number of filter parameters is \n"
  syntax:
    content: convolution(convolution_map, operand, strides=(1,), sharing=[True], auto_padding=[True],
      dilation=(1,), reduction_rank=1, groups=1, max_temp_mem_size_in_samples=0, name='')
    parameters:
    - description: 'convolution filter weights, stored as a tensor of dimensions ,

        where  must be the kernel dimensions (spatial extent of the filter).

        '
      id: convolution_map
    - description: 'convolution input. A tensor with dimensions .

        '
      id: operand
    - description: 'stride dimensions. If strides[i] > 1 then only pixel positions
        that are multiples of strides[i] are computed.

        For example, a stride of 2 will lead to a halving of that dimension. The first
        stride dimension that lines up with the number

        of input channels can be set to any non-zero value.

        '
      id: strides
      type:
      - tuple, optional
    - description: 'sharing flags for each input dimension

        '
      id: sharing
      type:
      - bool
    - description: 'flags for each input dimension whether it should be padded automatically
        (that is,

        symmetrically) or not padded at all. Padding means that the convolution kernel
        is applied to all pixel positions, where all

        pixels outside the area are assumed zero ("padded with zeroes"). Without padding,
        the kernels are only shifted over

        positions where all inputs to the kernel still fall inside the area. In this
        case, the output dimension will be less than

        the input dimension. The last value that lines up with the number of input
        channels must be false.

        '
      id: auto_padding
      type:
      - bool
    - description: 'the dilation value along each axis, default 1 mean no dilation.

        '
      id: dilation
      type:
      - tuple, optional
    - description: 'must be 0 or 1, 0 mean no depth or channel dimension in the input
        and 1 mean the input has channel or depth dimension.

        '
      id: reduction_rank
      type:
      - int, default 1
    - description: 'number of groups during convolution, that controls the connections
        between input and output channels. Deafult value is 1,

        which means that all input channels are convolved to produce all output channels.
        A value of N would mean that the input (and output) channels are

        divided into N groups with the input channels in one group (say i-th input
        group) contributing to output channels in only one group (i-th output group).

        Number of input and output channels must be divisble by value of groups argument.
        Also, value of this argument must be strictly positive, i.e. groups > 0.

        '
      id: groups
      type:
      - int, default 1
    - description: 'maximum amount of auxiliary memory (in samples) that should be
        reserved to perform convolution

        operations. Some convolution engines (e.g. cuDNN and GEMM-based engines) can
        benefit from using workspace as it may improve

        performance. However, sometimes this may lead to higher memory utilization.
        Default is 0 which means the same as the input

        samples.

        '
      id: max_temp_mem_size_in_samples
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.convolution
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(9.0, dtype = np.float32), (1, 3, 3))\n\
    >>> x = C.input_variable(img.shape)\n>>> filter = np.reshape(np.array([2, -1,\
    \ -1, 2], dtype = np.float32), (1, 2, 2))\n>>> kernel = C.constant(value = filter)\n\
    >>> np.round(C.convolution_transpose(kernel, x, auto_padding = [False]).eval({x:\
    \ [img]}),5)\narray([[[[  0.,   2.,   3.,  -2.],\n          [  6.,   4.,   6.,\
    \  -1.],\n          [  9.,  10.,  12.,   2.],\n          [ -6.,   5.,   6.,  16.]]]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.convolution_transpose
  langs:
  - python
  module: cntk.ops
  name: convolution_transpose
  source:
    id: convolution_transpose
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 357
  summary: "Computes the transposed convolution of `convolution_map` (typically a\
    \ tensor of learnable parameters) with\n`operand` (commonly an image or output\
    \ of a previous convolution/pooling operation).\nThis is also known as `fractionally\
    \ strided convolutional layers`, or, `deconvolution`.\nThis operation is used\
    \ in image and language processing applications. It supports arbitrary\ndimensions,\
    \ strides, sharing, and padding.\n\nThis function operates on input tensors with\
    \ dimensions . This can be understood as a rank-n\nobject, where each entry consists\
    \ of a -dimensional vector. For example, an RGB image would have dimensions\n\
    , i.e. a -sized structure, where each entry (pixel) consists of a 3-tuple.\n\n\
    *convolution_transpose* convolves the input `operand` with a  rank tensor of (typically\
    \ learnable) filters called\n`convolution_map` of shape  (typically ).\nThe first\
    \ dimension, , must match the number of channels in the input. The second dimension,\
    \ , is the number of convolution filters (i.e. the number of\nchannels in the\
    \ output).\nThe last n dimensions are the spatial extent of the filter. I.e. for\
    \ each output position, a vector of\ndimension  is computed. Hence, the total\
    \ number of filter parameters is \n"
  syntax:
    content: convolution_transpose(convolution_map, operand, strides=(1,), sharing=[True],
      auto_padding=[True], output_shape=None, dilation=(1,), reduction_rank=1, max_temp_mem_size_in_samples=0,
      name='')
    parameters:
    - description: 'convolution filter weights, stored as a tensor of dimensions ,

        where  must be the kernel dimensions (spatial extent of the filter).

        '
      id: convolution_map
    - description: 'convolution input. A tensor with dimensions .

        '
      id: operand
    - description: 'stride dimensions. If strides[i] > 1 then only pixel positions
        that are multiples of strides[i] are computed.

        For example, a stride of 2 will lead to a halving of that dimension. The first
        stride dimension that lines up with the number

        of input channels can be set to any non-zero value.

        '
      id: strides
      type:
      - tuple, optional
    - description: 'sharing flags for each input dimension

        '
      id: sharing
      type:
      - bool
    - description: 'flags for each input dimension whether it should be padded automatically
        (that is,

        symmetrically) or not padded at all. Padding means that the convolution kernel
        is applied to all pixel positions, where all

        pixels outside the area are assumed zero ("padded with zeroes"). Without padding,
        the kernels are only shifted over

        positions where all inputs to the kernel still fall inside the area. In this
        case, the output dimension will be less than

        the input dimension. The last value that lines up with the number of input
        channels must be false.

        '
      id: auto_padding
      type:
      - bool
    - description: 'user expected output shape after convolution transpose.

        '
      id: output_shape
    - description: 'the dilation value along each axis, default 1 mean no dilation.

        '
      id: dilation
      type:
      - tuple, optional
    - description: 'must be 0 or 1, 0 mean no depth or channel dimension in the input
        and 1 mean the input has channel or depth dimension.

        '
      id: reduction_rank
      type:
      - int, default 1
    - description: 'maximum amount of auxiliary memory (in samples) that should be
        reserved to perform convolution

        operations. Some convolution engines (e.g. cuDNN and GEMM-based engines) can
        benefit from using workspace as it may improve

        performance. However, sometimes this may lead to higher memory utilization.
        Default is 0 which means the same as the input

        samples.

        '
      id: max_temp_mem_size_in_samples
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.convolution_transpose
- example:
  - "\n```\n\n>>> np.round(C.cos(np.arccos([[1,0.5],[-0.25,-0.75]])).eval(),5)\narray([[\
    \ 1.  ,  0.5 ],\n       [-0.25, -0.75]], dtype=float32)\n```\n"
  fullName: cntk.ops.cos
  langs:
  - python
  module: cntk.ops
  name: cos
  source:
    id: cos
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1615
  summary: 'Computes the element-wise cosine of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: cos(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.cos
- example:
  - "\n```\n\n>>> np.round(C.cosh([[1,0.5],[-0.25,-0.75]]).eval(),5)\narray([[ 1.54308,\
    \  1.12763],\n       [ 1.03141,  1.29468]], dtype=float32)\n```\n"
  fullName: cntk.ops.cosh
  langs:
  - python
  module: cntk.ops
  name: cosh
  source:
    id: cosh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1703
  summary: 'Computes the element-wise cosh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: cosh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.cosh
- fullName: cntk.ops.crop_automatic
  langs:
  - python
  module: cntk.ops
  name: crop_automatic
  source:
    id: crop_automatic
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3756
  summary: 'Crops input along spatial dimensions so that it matches spatial size of
    reference input.


    Crop offsets are computed by traversing the network graph and computing affine
    transform

    between the two inputs. Translation part of the transform determines the offsets.
    The transform

    is computed as composition of the transforms between each input and their common
    ancestor.

    The common ancestor is expected to exist.

    '
  syntax:
    content: crop_automatic(node_input, node_referent, name='')
    parameters:
    - description: 'class:*~cntk.ops.functions.Function* that outputs the tensor to
        be cropped

        '
      id: node_input
    - description: 'class:*~cntk.ops.functions.Function* that outputs the reference
        tensor

        '
      id: node_referent
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.crop_automatic
- fullName: cntk.ops.crop_automatic_with_ancestors
  langs:
  - python
  module: cntk.ops
  name: crop_automatic_with_ancestors
  source:
    id: crop_automatic_with_ancestors
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3778
  summary: 'Crops input along spatial dimensions so that it matches spatial size of
    reference input.


    Crop offsets are computed by traversing the network graph and computing affine
    transform

    between the two inputs. Translation part of the transform determines the offsets.
    The transform

    is computed as composition of the transforms between each input and their common
    ancestor.


    ancestor_input and ancestor_referent are expected to be ancestors of node_input
    and

    node_referent, respectively. They act like the same node for the purpose of finding
    a common

    ancestor. They are used in cases when node_input and node_referent do not have
    a common

    ancestor in the network. Typically, the ancestor nodes have the same spatial size.
    For example, in

    pixelwise semantic labeling, ancestor_input would be the input image, and ancestor_referent
    would

    be the ground truth image containing pixelwise labels.

    '
  syntax:
    content: crop_automatic_with_ancestors(node_input, node_referent, ancestor_input,
      ancestor_referent, name='')
    parameters:
    - description: 'class:*~cntk.ops.functions.Function* that outputs the tensor to
        be cropped

        '
      id: node_input
    - description: 'class:*~cntk.ops.functions.Function* that outputs the reference
        tensor

        '
      id: node_referent
    - description: 'class:*~cntk.ops.functions.Function* that outputs ancestor of
        node_input

        '
      id: ancestor_input
      type:
      - optional
    - description: 'class:*~cntk.ops.functions.Function* that outputs ancestor of
        node_referent

        '
      id: ancestor_referent
      type:
      - optional
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.crop_automatic_with_ancestors
- fullName: cntk.ops.crop_manual
  langs:
  - python
  module: cntk.ops
  name: crop_manual
  source:
    id: crop_manual
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3736
  summary: 'Crops input along spatial dimensions so that it matches spatial size of
    reference input.

    Crop offsets are given in pixels.

    '
  syntax:
    content: crop_manual(node_input, node_referent, offset_x, offset_y, name='')
    parameters:
    - description: 'class:*~cntk.ops.functions.Function* that outputs the tensor to
        be cropped

        '
      id: node_input
    - description: 'class:*~cntk.ops.functions.Function* that outputs the reference
        tensor

        '
      id: node_referent
    - description: 'horizontal crop offset

        '
      id: offset_x
      type:
      - int
    - description: 'vertical crop offset

        '
      id: offset_y
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.crop_manual
- example:
  - "\n```\n\n>>> x = np.array(np.reshape(range(8), (8, 1, 1)), dtype=np.float32)\n\
    >>> x = np.tile(x, (1, 2, 3))\n>>> a = C.input_variable((8, 2, 3))\n>>> d2s_op\
    \ = C.depth_to_space(a, block_size=2)\n>>> d2s_op.eval({a:x})\narray([[[[ 0.,\
    \  1.,  0.,  1.,  0.,  1.],\n         [ 2.,  3.,  2.,  3.,  2.,  3.],\n      \
    \   [ 0.,  1.,  0.,  1.,  0.,  1.],\n         [ 2.,  3.,  2.,  3.,  2.,  3.]],\n\
    <BLANKLINE>\n        [[ 4.,  5.,  4.,  5.,  4.,  5.],\n         [ 6.,  7.,  6.,\
    \  7.,  6.,  7.],\n         [ 4.,  5.,  4.,  5.,  4.,  5.],\n         [ 6.,  7.,\
    \  6.,  7.,  6.,  7.]]]], dtype=float32)\n```\n"
  fullName: cntk.ops.depth_to_space
  langs:
  - python
  module: cntk.ops
  name: depth_to_space
  seealsoContent: "See also: [1] W. Shi et. al. [: Real-Time Single Image and Video\
    \ Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network](https://arxiv.org/abs/1609.05158).\
    \ \n"
  source:
    id: depth_to_space
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3810
  summary: 'Rearranges elements in the input tensor from the depth dimension into
    spatial blocks.


    This operation is useful for implementing sub-pixel convolution that is part of
    models

    for image super-resolution (see [1]). It rearranges elements of an input tensor
    of shape

    (Cxbxb, H, W) to a tensor of shape (C, bxH, bxW), where b is the *block_size*.

    '
  syntax:
    content: depth_to_space(operand, block_size, name='')
    parameters:
    - description: 'Input tensor, with dimensions .

        '
      id: operand
    - description: 'Integer value. This defines the size of the spatial block where
        the

        depth elements move to. Number of channels, C, in the input tensor must be
        divisible

        by math:*(block_size times block_size)*

        '
      id: block_size
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.depth_to_space
- example:
  - "\n```\n\n>>> data = [[10, 20],[30, 40],[50, 60]]\n>>> C.dropout(data, 0.5).eval()\
    \ # doctest: +SKIP\narray([[  0.,  40.],\n       [  0.,  80.],\n       [  0.,\
    \   0.]], dtype=float32)\n```\n\n\n```\n\n>>> C.dropout(data, 0.75).eval() # doctest:\
    \ +SKIP\narray([[   0.,    0.],\n       [   0.,  160.],\n       [   0.,  240.]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.dropout
  langs:
  - python
  module: cntk.ops
  name: dropout
  source:
    id: dropout
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3390
  summary: 'Each element of the input is independently set to 0 with probability `dropout_rate`

    or to 1 / (1 - `dropout_rate`) times its original value (with probability 1-`dropout_rate`).

    Dropout is a good way to reduce overfitting.


    This behavior only happens during training. During inference dropout is a no-op.

    In the paper that introduced dropout it was suggested to scale the weights during
    inference.

    In CNTK''s implementation, because the values that are not set to 0 are multiplied

    with (1 / (1 - `dropout_rate`)), this is not necessary.

    '
  syntax:
    content: dropout(x, dropout_rate=0.0, seed=4294967293, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'probability that an element of `x` will be set to zero

        '
      id: dropout_rate
      type:
      - float, [0,1)
    - description: 'random seed.

        '
      id: seed
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - cntk.ops.str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.dropout
- example:
  - '

    ```


    >>> C.element_and([1, 1, 0, 0], [1, 0, 1, 0]).eval()

    array([ 1.,  0.,  0.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_and
  langs:
  - python
  module: cntk.ops
  name: element_and
  source:
    id: element_and
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2009
  summary: 'Computes the element-wise logic AND of `x`.

    '
  syntax:
    content: element_and(x, y, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_and
- example:
  - '

    ```


    >>> C.element_divide([1., 1., 1., 1.], [0.5, 0.25, 0.125, 0.]).eval()

    array([ 2.,  4.,  8.,  0.], dtype=float32)

    ```



    ```


    >>> C.element_divide([5., 10., 15., 30.], [2.]).eval()

    array([  2.5,   5. ,   7.5,  15. ], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_divide
  langs:
  - python
  module: cntk.ops
  name: element_divide
  source:
    id: element_divide
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 996
  summary: 'The output of this operation is the element-wise division of the two input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_divide(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_divide
- fullName: cntk.ops.element_max
  langs:
  - python
  module: cntk.ops
  name: element_max
  source:
    id: element_max
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 954
  summary: 'The output of this operation is the element-wise max of the two or more
    input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_max(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id002
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id002
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_max
- fullName: cntk.ops.element_min
  langs:
  - python
  module: cntk.ops
  name: element_min
  source:
    id: element_min
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 975
  summary: 'The output of this operation is the element-wise min of the two or more
    input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_min(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id003
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id003
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_min
- example:
  - '

    ```


    >>> C.element_not([1, 1, 0, 0]).eval()

    array([ 0.,  0.,  1.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_not
  langs:
  - python
  module: cntk.ops
  name: element_not
  source:
    id: element_not
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2029
  summary: 'Computes the element-wise logic NOT of `x` and `y`.

    '
  syntax:
    content: element_not(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: y
      type:
      - x,
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_not
- example:
  - '

    ```


    >>> C.element_or([1, 1, 0, 0], [1, 0, 1, 0]).eval()

    array([ 1.,  1.,  1.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_or
  langs:
  - python
  module: cntk.ops
  name: element_or
  source:
    id: element_or
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2048
  summary: 'Computes the element-wise logic OR of `x` and `y`.

    '
  syntax:
    content: element_or(x, y, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: y
      type:
      - x,
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_or
- example:
  - '

    ```


    >>> C.element_select([-10, -1, 0, 0.3, 100], [1, 10, 100, 1000, 10000], [ 2, 20,
    200, 2000, 20000]).eval()

    array([     1.,     10.,    200.,   1000.,  10000.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_select
  langs:
  - python
  module: cntk.ops
  name: element_select
  source:
    id: element_select
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2186
  summary: 'return either `value_if_true` or `value_if_false` based on the value of
    `flag`.

    If `flag` != 0 `value_if_true` is returned, otherwise `value_if_false`.

    Behaves analogously to numpy.where(...).

    '
  syntax:
    content: element_select(flag, value_if_true, value_if_false, name='')
    parameters:
    - description: 'condition tensor

        '
      id: flag
    - description: 'true branch tensor

        '
      id: value_if_true
    - description: 'false branch tensor

        '
      id: value_if_false
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_select
- example:
  - '

    ```


    >>> C.element_times([1., 1., 1., 1.], [0.5, 0.25, 0.125, 0.]).eval()

    array([ 0.5  ,  0.25 ,  0.125,  0.   ], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.]).eval()

    array([ 10.,  20.,  30.,  60.], dtype=float32)

    ```



    ```


    >>> C.element_times([5., 10., 15., 30.], [2.], [1., 2., 1., 2.]).eval()

    array([  10.,   40.,   30.,  120.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_times
  langs:
  - python
  module: cntk.ops
  name: element_times
  source:
    id: element_times
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 923
  summary: 'The output of this operation is the element-wise product of the two or
    more input

    tensors. It supports broadcasting.

    '
  syntax:
    content: element_times(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id004
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id004
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_times
- example:
  - '

    ```


    >>> C.element_xor([1, 1, 0, 0], [1, 0, 1, 0]).eval()

    array([ 0.,  1.,  1.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.element_xor
  langs:
  - python
  module: cntk.ops
  name: element_xor
  source:
    id: element_xor
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2068
  summary: 'Computes the element-wise logic XOR of `x` and `y`.

    '
  syntax:
    content: element_xor(x, y, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: y
      type:
      - x,
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.element_xor
- example:
  - '

    ```


    >>> C.elu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[-0.632121, -0.393469,  0.      ,  1.      ,  2.      ]], dtype=float32)

    ```

    '
  fullName: cntk.ops.elu
  langs:
  - python
  module: cntk.ops
  name: elu
  source:
    id: elu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1365
  summary: 'Exponential linear unit operation. Computes the element-wise exponential
    linear

    of `x`: `max(x, 0)` for `x >= 0` and `x`: `exp(x)-1` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: elu(x, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.elu
- example:
  - '

    ```


    >>> C.equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 0.,  1.,  0.], dtype=float32)

    ```



    ```


    >>> C.equal([-1,0,1], [1]).eval()

    array([ 0.,  0.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.equal
  langs:
  - python
  module: cntk.ops
  name: equal
  source:
    id: equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 649
  summary: 'Elementwise ''equal'' comparison of two tensors. Result is 1 if values
    are equal 0 otherwise.

    '
  syntax:
    content: equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.equal
- example:
  - '

    ```


    >>> C.exp([0., 1.]).eval()

    array([ 1.      ,  2.718282], dtype=float32)

    ```

    '
  fullName: cntk.ops.exp
  langs:
  - python
  module: cntk.ops
  name: exp
  source:
    id: exp
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1894
  summary: 'Computes the element-wise exponential of `x`:


    '
  syntax:
    content: exp(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.exp
- example:
  - "\n```\n\n>>> x0 = np.arange(12).reshape((2, 2, 3)).astype('f')\n>>> x = C.input_variable((2,\
    \ 3))\n>>> C.expand_dims(x, 0).eval({x: x0})\narray([[[[  0.,   1.,   2.]],\n\
    <BLANKLINE>\n        [[  3.,   4.,   5.]]],\n<BLANKLINE>\n<BLANKLINE>\n      \
    \ [[[  6.,   7.,   8.]],\n<BLANKLINE>\n        [[  9.,  10.,  11.]]]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.expand_dims
  langs:
  - python
  module: cntk.ops
  name: expand_dims
  source:
    id: expand_dims
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2366
  summary: '   Adds a singleton (size 1) axis at position `axis`.

    '
  syntax:
    content: expand_dims(x, axis, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'The position to insert the singleton axis.

        '
      id: axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.expand_dims
- example:
  - "\n```\n\n>>> # create 2x3x4 matrix, flatten the matrix at axis = 1\n>>> shape\
    \ = (2, 3, 4)\n>>> data = np.reshape(np.arange(np.prod(shape), dtype = np.float32),\
    \ shape)\n>>> C.flatten(data, 1).eval()\narray([[  0.,   1.,   2.,   3.,   4.,\
    \   5.,   6.,   7.,   8.,   9.,  10.,\n         11.],\n       [ 12.,  13.,  14.,\
    \  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n         23.]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.flatten
  langs:
  - python
  module: cntk.ops
  name: flatten
  source:
    id: flatten
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2751
  summary: 'Flattens the input tensor into a 2D matrix.

    If the input tensor has shape (d_0, d_1, ... d_n) then the output will have shape
    (d_0 X d_1 ... d_(axis-1), d_axis X d_(axis+1) ... X dn).

    '
  syntax:
    content: flatten(x, axis=None, name='')
    parameters:
    - description: 'Input tensor.

        '
      id: x
    - description: '(Default to 0) Indicates up to which input dimensions (exclusive)
        should be flattened to the outer dimension of the output

        '
      id: axis
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.flatten
- example:
  - "\n```\n\n>>> C.floor([0.2, 1.3, 4., 5.5, 0.0]).eval()\narray([ 0.,  1.,  4.,\
    \  5.,  0.], dtype=float32)\n```\n\n\n```\n\n>>> C.floor([[0.6, 3.3], [1.9, 5.6]]).eval()\n\
    array([[ 0.,  3.],\n       [ 1.,  5.]], dtype=float32)\n```\n\n\n```\n\n>>> C.floor([-5.5,\
    \ -4.2, -3., -0.7, 0]).eval()\narray([-6., -5., -3., -1.,  0.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> C.floor([[-0.6, -4.3], [1.9, -3.2]]).eval()\narray([[-1.,\
    \ -5.],\n       [ 1., -4.]], dtype=float32)\n```\n"
  fullName: cntk.ops.floor
  langs:
  - python
  module: cntk.ops
  name: floor
  source:
    id: floor
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1213
  summary: 'The output of this operation is the element wise value rounded to the
    largest

    integer less than or equal to the input.

    '
  syntax:
    content: floor(arg, name='')
    parameters:
    - description: 'input tensor

        '
      id: arg
    - description: 'the name of the Function instance in the network (optional)

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.floor
- fullName: cntk.ops.forward_backward
  langs:
  - python
  module: cntk.ops
  name: forward_backward
  source:
    id: forward_backward
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 263
  summary: "Criterion node for training methods that rely on forward-backward Viterbi-like\
    \ passes, e.g. Connectionist Temporal Classification (CTC) training\nThe node\
    \ takes as the input the graph of labels, produced by the labels_to_graph operation\
    \ that determines the exact forward/backward procedure.\n.. admonition:: Example\n\
    \n   graph = cntk.labels_to_graph(labels)\n   networkOut = model(features)\n \
    \  fb = C.forward_backward(graph, networkOut, 132)\n"
  syntax:
    content: forward_backward(graph, features, blankTokenId, delayConstraint=-1, name='')
    parameters:
    - description: 'labels graph

        '
      id: graph
    - description: 'network output

        '
      id: features
    - description: 'id of the CTC blank label

        '
      id: blankTokenId
    - description: 'label output delay constraint introduced during training that
        allows to have shorter delay during inference. This is using the original
        time information to enforce that CTC tokens only get aligned within a time
        margin. Setting this parameter smaller will result in shorted delay between
        label output during decoding, yet may hurt accuracy. delayConstraint=-1 means
        no constraint

        '
      id: delayConstraint
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.forward_backward
- example:
  - "\n```\n\n>>> c = np.asarray([[[0],[1]],[[4],[5]]]).astype('f')\n>>> x = C.input_variable((2,1))\n\
    >>> d = np.arange(12).reshape(6,2).astype('f')\n>>> y = C.constant(d)\n>>> C.gather(y,\
    \ x).eval({x:c})\narray([[[[  0.,   1.]],\n<BLANKLINE>\n        [[  2.,   3.]]],\n\
    <BLANKLINE>\n<BLANKLINE>\n       [[[  8.,   9.]],\n<BLANKLINE>\n        [[ 10.,\
    \  11.]]]], dtype=float32)\n```\n"
  fullName: cntk.ops.gather
  langs:
  - python
  module: cntk.ops
  name: gather
  source:
    id: gather
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2713
  summary: 'Retrieves the elements of indices in the tensor reference.

    '
  syntax:
    content: gather(reference, indices, axis=None, name='')
    parameters:
    - description: 'A tensor of values

        '
      id: reference
    - description: 'A tensor of indices

        '
      id: indices
    - description: 'The axis along which the indices refer to. Default (None) means
        the  first axis.

        '
      id: axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.gather
- example:
  - '

    ```


    >>> C.greater([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 0.,  0.,  1.], dtype=float32)

    ```



    ```


    >>> C.greater([-1,0,1], [0]).eval()

    array([ 0.,  0.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.greater
  langs:
  - python
  module: cntk.ops
  name: greater
  source:
    id: greater
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 675
  summary: 'Elementwise ''greater'' comparison of two tensors. Result is 1 if left
    > right else 0.

    '
  syntax:
    content: greater(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.greater
- example:
  - '

    ```


    >>> C.greater_equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 0.,  1.,  1.], dtype=float32)

    ```



    ```


    >>> C.greater_equal([-1,0,1], [0]).eval()

    array([ 0.,  1.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.greater_equal
  langs:
  - python
  module: cntk.ops
  name: greater_equal
  source:
    id: greater_equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 701
  summary: 'Elementwise ''greater equal'' comparison of two tensors. Result is 1 if
    left >= right else 0.

    '
  syntax:
    content: greater_equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.greater_equal
- example:
  - '

    ```


    >>> alpha = 1

    >>> beta = 2

    >>> C.hard_sigmoid([-2.5, -1.5, 1], alpha, beta).eval()

    array([ 0. ,  0.5,  1. ], dtype=float32)

    ```

    '
  fullName: cntk.ops.hard_sigmoid
  langs:
  - python
  module: cntk.ops
  name: hard_sigmoid
  source:
    id: hard_sigmoid
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1871
  summary: 'Computes the element-wise HardSigmoid function, y = max(0, min(1, alpha
    * x + beta)).

    '
  syntax:
    content: hard_sigmoid(x, alpha, beta, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the alpha term of the above equation.

        '
      id: alpha
      type:
      - float
    - description: 'the beta term of the above equation.

        '
      id: beta
      type:
      - float
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.hard_sigmoid
- example:
  - '

    ```


    >>> C.hardmax([1., 1., 2., 3.]).eval()

    array([ 0.,  0.,  0.,  1.], dtype=float32)

    ```



    ```


    >>> C.hardmax([1., 3., 2., 3.]).eval()

    array([ 0.,  1.,  0.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.hardmax
  langs:
  - python
  module: cntk.ops
  name: hardmax
  source:
    id: hardmax
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1815
  summary: 'Creates a tensor with the same shape as the input tensor, with zeros everywhere
    and a 1.0 where the

    maximum value of the input tensor is located. If the maximum value is repeated,
    1.0 is placed in the first location found.

    '
  syntax:
    content: hardmax(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.hardmax
- fullName: cntk.ops.image_scaler
  langs:
  - python
  module: cntk.ops
  name: image_scaler
  source:
    id: image_scaler
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3138
  summary: 'Alteration of image by scaling its individual values.

    '
  syntax:
    content: image_scaler(x, scalar, biases, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'Scalar channel factor.

        '
      id: scalar
      type:
      - float
    - description: 'Bias values for each channel.

        '
      id: bias
      type:
      - numpy array
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.image_scaler
- fullName: cntk.ops.input
  langs:
  - python
  module: cntk.ops
  name: input
  source:
    id: input
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3447
  summary: 'DEPRECATED.


    It creates an input in the network: a place where data,

    such as features and labels, should be provided.

    '
  syntax:
    content: input(shape, dtype=<cntk.default_options.default_override_or object>,
      needs_gradient=False, is_sparse=False, dynamic_axes=[Axis('defaultBatchAxis')],
      name='')
    parameters:
    - description: 'the shape of the input tensor

        '
      id: shape
      type:
      - tuple
      - int
    - description: 'data type. Default is np.float32.

        '
      id: dtype
      type:
      - np.float32
      - np.float64
      - np.float16
    - description: 'whether to back-propagates to it or not. False by default.

        '
      id: needs_gradient
      type:
      - bool, optional
    - description: 'whether the variable is sparse (*False* by default)

        '
      id: is_sparse
      type:
      - bool, optional
    - description: 'a list of dynamic axis (e.g., batch axis, sequence axis)

        '
      id: dynamic_axes
      type:
      - list
      - tuple, default
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable

        '
  type: function
  uid: cntk.ops.input
- fullName: cntk.ops.input_variable
  langs:
  - python
  module: cntk.ops
  name: input_variable
  source:
    id: input_variable
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3473
  summary: 'It creates an input in the network: a place where data,

    such as features and labels, should be provided.

    '
  syntax:
    content: input_variable(shape, dtype=np.float32, needs_gradient=False, is_sparse=False,
      dynamic_axes=[Axis.default_batch_axis()], name='')
    parameters:
    - description: 'the shape of the input tensor

        '
      id: shape
      type:
      - tuple
      - int
    - description: 'data type. Default is np.float32.

        '
      id: dtype
      type:
      - np.float32
      - np.float64
      - np.float16
    - description: 'whether to back-propagates to it or not. False by default.

        '
      id: needs_gradient
      type:
      - bool, optional
    - description: 'whether the variable is sparse (*False* by default)

        '
      id: is_sparse
      type:
      - bool, optional
    - description: 'a list of dynamic axis (e.g., batch axis, time axis)

        '
      id: dynamic_axes
      type:
      - list
      - tuple, default
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable

        '
  type: function
  uid: cntk.ops.input_variable
- example:
  - '

    ```


    >>> num_classes = 2

    >>> labels = C.input_variable((num_classes))

    >>> graph = C.labels_to_graph(labels)

    ```

    '
  fullName: cntk.ops.labels_to_graph
  langs:
  - python
  module: cntk.ops
  name: labels_to_graph
  source:
    id: labels_to_graph
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 242
  summary: 'Conversion node from labels to graph. Typically used as an input to ForwardBackward
    node.

    This node''s objective is to transform input labels into a graph representing
    exact forward-backward criterion.

    '
  syntax:
    content: labels_to_graph(labels, name='')
    parameters:
    - description: 'input training labels

        '
      id: labels
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.labels_to_graph
- example:
  - '

    ```


    >>> C.leaky_relu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[-0.01 , -0.005,  0.   ,  1.   ,  2.   ]], dtype=float32)

    ```

    '
  fullName: cntk.ops.leaky_relu
  langs:
  - python
  module: cntk.ops
  name: leaky_relu
  source:
    id: leaky_relu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1414
  summary: 'Leaky Rectified linear operation. Computes the element-wise leaky rectified
    linear

    of `x`: `max(x, 0)` for `x >= 0` and `x`: `alpha*x` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: leaky_relu(x, alpha=0.01, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'the alpha term of the above equation.

        '
      id: alpha
      type:
      - float
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.leaky_relu
- example:
  - '

    ```


    >>> C.less([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 1.,  0.,  0.], dtype=float32)

    ```



    ```


    >>> C.less([-1,0,1], [0]).eval()

    array([ 1.,  0.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.less
  langs:
  - python
  module: cntk.ops
  name: less
  source:
    id: less
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 623
  summary: 'Elementwise ''less'' comparison of two tensors. Result is 1 if left <
    right else 0.

    '
  syntax:
    content: less(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.less
- example:
  - '

    ```


    >>> C.less_equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 1.,  1.,  0.], dtype=float32)

    ```



    ```


    >>> C.less_equal([-1,0,1], [0]).eval()

    array([ 1.,  1.,  0.], dtype=float32)

    ```

    '
  fullName: cntk.ops.less_equal
  langs:
  - python
  module: cntk.ops
  name: less_equal
  source:
    id: less_equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 753
  summary: 'Elementwise ''less equal'' comparison of two tensors. Result is 1 if left
    <= right else 0.

    '
  syntax:
    content: less_equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.less_equal
- fullName: cntk.ops.local_response_normalization
  langs:
  - python
  module: cntk.ops
  name: local_response_normalization
  source:
    id: local_response_normalization
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 591
  summary: "Local Response Normalization layer. See Section 3.3 of the paper:\n\n\
    [https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n\
    \nThe mathematical equation is:\n\n`b_{x,y}^i=a_{x,y}^i/(bias+\alpha\\sum_{j=max(0,i-depth_radius)}^{min(N-1,\
    \ i+depth_radius)}(a_{x,y}^j)^2)^\beta`\n\nwhere a_{x,y}^i is the activity of\
    \ a neuron computed by applying kernel i at position (x,y)\nN is the total number\
    \ of kernels, depth_radius is half normalization width.\n"
  syntax:
    content: local_response_normalization(operand, depth_radius, bias, alpha, beta,
      name='')
    parameters:
    - description: 'input of the Local Response Normalization.

        '
      id: operand
    - description: 'the radius on the channel dimension to apply the normalization.

        '
      id: depth_radius
      type:
      - int
    - description: 'a bias term to avoid divide by zero.

        '
      id: bias
      type:
      - double
    - description: 'the alpha term of the above equation.

        '
      id: alpha
      type:
      - double
    - description: 'the beta term of the above equation.

        '
      id: beta
      type:
      - double
    - description: 'the name of the Function instance in the network.

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.local_response_normalization
- example:
  - '

    ```


    >>> C.log([1., 2.]).eval()

    array([ 0.      ,  0.693147], dtype=float32)

    ```

    '
  fullName: cntk.ops.log
  langs:
  - python
  module: cntk.ops
  name: log
  source:
    id: log
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1916
  summary: "Computes the element-wise the natural logarithm of `x`:\n\nNote: CNTK\
    \ returns -85.1 for log(x) if `x` is negative or zero. The reason is that it uses\
    \ 1e-37 (whose natural logarithm is -85.1) as the smallest float number for *log*,\
    \ because this is the only guaranteed precision across platforms. This will be\
    \ changed to return *NaN* and *-inf*. \n"
  syntax:
    content: log(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.log
- example:
  - '

    ```


    >>> a = np.arange(3,dtype=np.float32)

    >>> np.exp(C.log_add_exp(np.log(1+a), np.log(1+a*a)).eval())

    array([ 2.,  4.,  8.], dtype=float32)

    >>> np.exp(C.log_add_exp(np.log(1+a), [0.]).eval())

    array([ 2.,  3.,  4.], dtype=float32)

    ```

    '
  fullName: cntk.ops.log_add_exp
  langs:
  - python
  module: cntk.ops
  name: log_add_exp
  source:
    id: log_add_exp
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1023
  summary: 'Calculates the log of the sum of the exponentials

    of the two or more input tensors. It supports broadcasting.

    '
  syntax:
    content: log_add_exp(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id005
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id005
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.log_add_exp
- fullName: cntk.ops.log_softmax
  langs:
  - python
  module: cntk.ops
  name: log_softmax
  source:
    id: log_softmax
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1747
  summary: 'Computes the logsoftmax normalized values of x. That is, y = x - log(reduce_sum(exp(x),
    axis)).

    '
  syntax:
    content: log_softmax(x, axis=None, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the axis of the inputs when coerced to 2D

        '
      id: axis
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.log_softmax
- example:
  - '

    ```


    >>> in1 = C.input_variable((4,))

    >>> in2 = C.input_variable((4,))

    >>> model = C.mean([in1, in2])

    >>> in1_data = np.asarray([[1., 2., 3., 4.]], np.float32)

    >>> in2_data = np.asarray([[0., 5., -3., 2.]], np.float32)

    >>> model.eval({in1: in1_data, in2: in2_data})

    array([[ 0.5,  3.5,  0. ,  3. ]], dtype=float32)

    ```

    '
  fullName: cntk.ops.mean
  langs:
  - python
  module: cntk.ops
  name: mean
  source:
    id: mean
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 84
  summary: '   Create a new Function instance that computes element-wise mean of input
    tensors.

    '
  syntax:
    content: mean(*operands, **kw_name)
    parameters:
    - description: 'list of functions

        '
      id: operands
      type:
      - list
    - description: 'the name of the mean Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.mean
- example:
  - "\n```\n\n>>> data = np.array([[[0., 2], [4., 6.]], [[0., 4], [8., 12.]]]).astype(np.float32)\n\
    >>> data\narray([[[  0.,   2.],\n        [  4.,   6.]],\n<BLANKLINE>\n       [[\
    \  0.,   4.],\n        [  8.,  12.]]], dtype=float32)\n>>> saved_precision = np.get_printoptions()['precision']\n\
    >>> np.set_printoptions(precision=4) # For consistent display upto 4 decimals.\n\
    >>> C.mean_variance_normalization(data).eval()\narray([[[-1.3416, -0.4472],\n\
    \        [ 0.4472,  1.3416]],\n<BLANKLINE>\n       [[-1.3416, -0.4472],\n    \
    \    [ 0.4472,  1.3416]]], dtype=float32)\n>>> np.set_printoptions(precision=saved_precision)\
    \ # Reseting the display precision.\n```\n"
  fullName: cntk.ops.mean_variance_normalization
  langs:
  - python
  module: cntk.ops
  name: mean_variance_normalization
  source:
    id: mean_variance_normalization
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3917
  summary: 'Computes mean-variance normalization of the specified input operand.


    This operation computes and mean and variance for the entire tensor if use_stats_across_channels
    is True.

    If use_stats_across_channels is False the computes mean and variance per channel
    and normalizes each

    channel with its own mean and variance. If do_variance_scaling is False, only
    the mean is subtracted,

    and the variance scaling is omitted.

    '
  syntax:
    content: mean_variance_normalization(operand, epsilon=1e-05, use_stats_across_channels=False,
      do_variance_scaling=True, name='')
    parameters:
    - description: 'Input tensor, with dimensions .

        '
      id: operand
    - description: 'epsilon added to the standard deviation to avoid division by 0.

        '
      id: epsilon
      type:
      - double, default 0.00001
    - description: 'If False, mean and variance are computed per channel.

        If True, mean and variance are computed over the entire tensor (all axes).

        '
      id: use_stats_across_channels
      type:
      - bool
    - description: 'If False, only the mean is subtracted. If True, it is also

        scaled by inverse of standard deviation.

        '
      id: do_variance_scaling
      type:
      - bool
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.mean_variance_normalization
- example:
  - "\n```\n\n>>> C.minus([1, 2, 3], [4, 5, 6]).eval()\narray([-3., -3., -3.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> C.minus([[1,2],[3,4]], 1).eval()\narray([[ 0.,  1.],\n   \
    \    [ 2.,  3.]], dtype=float32)\n```\n"
  fullName: cntk.ops.minus
  langs:
  - python
  module: cntk.ops
  name: minus
  source:
    id: minus
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 864
  summary: 'The output of this operation is left minus right tensor. It supports broadcasting.

    '
  syntax:
    content: minus(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.minus
- example:
  - '

    ```


    >>> C.negate([-1, 1, -2, 3]).eval()

    array([ 1., -1.,  2., -3.], dtype=float32)

    ```

    '
  fullName: cntk.ops.negate
  langs:
  - python
  module: cntk.ops
  name: negate
  source:
    id: negate
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2088
  summary: 'Computes the element-wise negation of `x`:


    '
  syntax:
    content: negate(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.negate
- example:
  - '

    ```


    >>> C.not_equal([41., 42., 43.], [42., 42., 42.]).eval()

    array([ 1.,  0.,  1.], dtype=float32)

    ```



    ```


    >>> C.not_equal([-1,0,1], [0]).eval()

    array([ 1.,  0.,  1.], dtype=float32)

    ```

    '
  fullName: cntk.ops.not_equal
  langs:
  - python
  module: cntk.ops
  name: not_equal
  source:
    id: not_equal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 727
  summary: 'Elementwise ''not equal'' comparison of two tensors. Result is 1 if left
    != right else 0.

    '
  syntax:
    content: not_equal(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side tensor

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.not_equal
- example:
  - "\n```\n\n>>> data = np.asarray([[1, 2],\n...                    [4, 5]], dtype=np.float32)\n\
    ```\n\n\n```\n\n>>> x = C.input_variable((2,))\n>>> C.one_hot(x, 6, False).eval({x:data})\n\
    array([[[ 0.,  1.,  0.,  0.,  0.,  0.],\n        [ 0.,  0.,  1.,  0.,  0.,  0.]],\n\
    <BLANKLINE>\n        [[ 0.,  0.,  0.,  0.,  1.,  0.],\n         [ 0.,  0.,  0.,\
    \  0.,  0.,  1.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.one_hot
  langs:
  - python
  module: cntk.ops
  name: one_hot
  source:
    id: one_hot
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2681
  summary: 'Create one hot tensor based on the input tensor

    '
  syntax:
    content: one_hot(x, num_classes, sparse_output=False, axis=-1, name='')
    parameters:
    - description: 'input tensor, the value must be positive integer and less than
        num_class

        '
      id: x
    - description: 'the number of class in one hot tensor

        '
      id: num_classes
    - description: 'if set as True, we will create the one hot tensor as sparse.

        '
      id: sparse_output
    - description: 'The axis to fill (default: -1, a new inner-most axis).

        '
      id: axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional, keyword only
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.one_hot
- example:
  - "\n```\n\n>>> x0 = np.arange(24).reshape((2, 3, 4)).astype('f')\n>>> x = C.input_variable((3,\
    \ 4))\n>>> C.ones_like(x).eval({x: x0})\narray([[[ 1.,  1.,  1.,  1.],\n     \
    \   [ 1.,  1.,  1.,  1.],\n        [ 1.,  1.,  1.,  1.]],\n<BLANKLINE>\n     \
    \  [[ 1.,  1.,  1.,  1.],\n        [ 1.,  1.,  1.,  1.],\n        [ 1.,  1., \
    \ 1.,  1.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.ones_like
  langs:
  - python
  module: cntk.ops
  name: ones_like
  source:
    id: ones_like
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2130
  summary: 'Creates an all-ones tensor with the same shape and dynamic axes as `x`:

    '
  syntax:
    content: ones_like(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.ones_like
- example:
  - "\n```\n\n>>> from _cntk_py import constant_initializer\n>>> W = C.parameter((C.InferredDimension,4),\
    \ constant_initializer(0.1))\n>>> x = C.input_variable(shape=(4,))\n>>> s = np.reshape(np.arange(20.0,\
    \ dtype=np.float32), (5,4))\n>>> t = np.reshape(np.arange(12.0, dtype=np.float32),\
    \ (3,4))\n>>> f = C.optimized_rnnstack(x, W, 8, 2) # doctest: +SKIP\n>>> r = f.eval({x:[s,t]})\
    \                # doctest: +SKIP\n>>> len(r)                               #\
    \ doctest: +SKIP\n2\n>>> print(*r[0].shape)                   # doctest: +SKIP\n\
    5 8\n>>> print(*r[1].shape)                   # doctest: +SKIP\n3 8\n>>> r[0][:3,:]-r[1]\
    \                      # doctest: +SKIP\narray([[ 0.,  0.,  0.,  0.,  0.,  0.,\
    \  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0., \
    \ 0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)\n```\n"
  fullName: cntk.ops.optimized_rnnstack
  langs:
  - python
  module: cntk.ops
  name: optimized_rnnstack
  source:
    id: optimized_rnnstack
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2213
  summary: 'An RNN implementation that uses the primitives in cuDNN.

    If cuDNN is not available it fails. You can use @cntk.misc.optimized_rnnstack_converter.convert_optimized_rnnstack

    to convert a model to GEMM-based implementation when no cuDNN.

    '
  syntax:
    content: optimized_rnnstack(operand, weights, hidden_size, num_layers, bidirectional=False,
      recurrent_op='lstm', name='')
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.optimized_rnnstack
- fullName: cntk.ops.output_variable
  langs:
  - python
  module: cntk.ops
  name: output_variable
  source:
    id: output_variable
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3508
  summary: 'It creates an output variable that is used to define a user defined function.

    '
  syntax:
    content: output_variable(shape, dtype, dynamic_axes, needs_gradient=True, name='')
    parameters:
    - description: 'the shape of the input tensor

        '
      id: shape
      type:
      - tuple
      - int
    - description: 'data type

        '
      id: dtype
      type:
      - np.float32
      - np.float64
      - np.float16
    - description: 'a list of dynamic axis (e.g., batch axis, time axis)

        '
      id: dynamic_axes
      type:
      - list
      - tuple
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable that is of output type

        '
  type: function
  uid: cntk.ops.output_variable
- example:
  - "\n```\n\n>>> data = np.arange(6, dtype=np.float32).reshape((2,3))\n>>> x = C.constant(value=data)\n\
    >>> C.pad(x, pattern=[(1,1),(2,2)], mode=C.ops.CONSTANT_PAD, constant_value=1).eval()\n\
    array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  0.,  1.,  2.,\
    \  1.,  1.],\n       [ 1.,  1.,  3.,  4.,  5.,  1.,  1.],\n       [ 1.,  1., \
    \ 1.,  1.,  1.,  1.,  1.]], dtype=float32)\n>>> C.pad(x, pattern=[(1,1),(2,2)],\
    \ mode=C.ops.REFLECT_PAD).eval()\narray([[ 5.,  4.,  3.,  4.,  5.,  4.,  3.],\n\
    \       [ 2.,  1.,  0.,  1.,  2.,  1.,  0.],\n       [ 5.,  4.,  3.,  4.,  5.,\
    \  4.,  3.],\n       [ 2.,  1.,  0.,  1.,  2.,  1.,  0.]], dtype=float32)\n>>>\
    \ C.pad(x, pattern=[(1,1),(2,2)], mode=C.ops.SYMMETRIC_PAD).eval()\narray([[ 1.,\
    \  0.,  0.,  1.,  2.,  2.,  1.],\n       [ 1.,  0.,  0.,  1.,  2.,  2.,  1.],\n\
    \       [ 4.,  3.,  3.,  4.,  5.,  5.,  4.],\n       [ 4.,  3.,  3.,  4.,  5.,\
    \  5.,  4.]], dtype=float32)\n```\n"
  fullName: cntk.ops.pad
  langs:
  - python
  module: cntk.ops
  name: pad
  source:
    id: pad
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2449
  summary: 'Pads a tensor according to the specified patterns.

    Three padding modes are supported: CONSTANT / REFLECT / SYMMETRIC.

    '
  syntax:
    content: pad(x, pattern, mode=0, constant_value=0, name='')
    parameters:
    - description: 'tensor to be padded.

        '
      id: x
    - description: 'how many values to add before and after the contents of the tensor
        in each dimension.

        '
      id: pattern
      type:
      - list of tuple with 2 integers
    - description: 'padding mode: C.ops.CONSTANT_PAD, C.ops.REFLECT_PAD and C.ops.SYMMETRIC_PAD

        '
      id: mode
      type:
      - int
    - description: 'the value used to fill the padding cells, only meaningful under
        CONSTANT mode.

        '
      id: constant_value
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.pad
- example:
  - '

    ```


    >>> alpha = C.constant(value=[[0.5, 0.5, 0.5, 0.5, 0.5]])

    >>> C.param_relu(alpha, [[-1, -0.5, 0, 1, 2]]).eval()

    array([[-0.5 , -0.25,  0.  ,  1.  ,  2.  ]], dtype=float32)

    ```

    '
  fullName: cntk.ops.param_relu
  langs:
  - python
  module: cntk.ops
  name: param_relu
  source:
    id: param_relu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1439
  summary: 'Parametric rectified linear operation. Computes the element-wise parameteric
    rectified linear

    of `x`: `max(x, 0)` for `x >= 0` and `x`: `alpha*x` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: param_relu(alpha, x, name='')
    parameters:
    - description: 'same shape as x

        '
      id: alpha
      type:
      - cntk.variables.Parameter
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.param_relu
- example:
  - "\n```\n\n>>> init_parameter = C.parameter(shape=(3,4), init=2)\n>>> np.asarray(init_parameter)\
    \ # doctest: +SKIP\narray([[ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.],\n\
    \       [ 2.,  2.,  2.,  2.]], dtype=float32)\n```\n"
  fullName: cntk.ops.parameter
  langs:
  - python
  module: cntk.ops
  name: parameter
  source:
    id: parameter
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3565
  summary: 'It creates a parameter tensor.

    '
  syntax:
    content: parameter(shape=None, init=None, dtype=None, device=None, name='')
    parameters:
    - description: 'the shape of the input tensor. If not provided, it

        will be inferred from `value`.

        '
      id: shape
      type:
      - tuple
      - int, optional
    - description: 'if init is a scalar

        it will be replicated for every element in the tensor or

        NumPy array. If it is the output of an initializer form

        @cntk.initializer it will be used to initialize the tensor at

        the first forward pass. If *None*, the tensor will be initialized

        with 0.

        '
      id: init
      type:
      - scalar
      - NumPy array
      - initializer
    - description: 'data type of the constant. If a NumPy array and `dtype`,

        are given, then data will be converted if needed. If none given, it will default
        to `np.float32`.

        '
      id: dtype
      type:
      - optional
    - description: 'instance of DeviceDescriptor

        '
      id: device
      type:
      - cntk.device.DeviceDescriptor
    - description: 'the name of the Parameter instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Parameter

        '
  type: function
  uid: cntk.ops.parameter
- fullName: cntk.ops.per_dim_mean_variance_normalize
  langs:
  - python
  module: cntk.ops
  name: per_dim_mean_variance_normalize
  source:
    id: per_dim_mean_variance_normalize
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3634
  summary: 'Computes per dimension mean-variance normalization of the specified input
    operand.

    '
  syntax:
    content: per_dim_mean_variance_normalize(operand, mean, inv_stddev, name='')
    parameters:
    - description: 'the variable to be normalized

        '
      id: operand
    - description: 'per dimension mean to use for the normalization

        '
      id: mean
      type:
      - NumPy array
    - description: 'per dimension standard deviation to use for the normalization

        '
      id: inv_stddev
      type:
      - NumPy array
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.per_dim_mean_variance_normalize
- fullName: cntk.ops.placeholder
  langs:
  - python
  module: cntk.ops
  name: placeholder
  source:
    id: placeholder
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3536
  summary: 'It creates a placeholder variable that has to be later bound to an actual
    variable.

    A common use of this is to serve as a placeholder for a later output variable
    in a

    recurrent network, which is replaced with the actual output variable by calling

    replace_placeholder(s).

    '
  syntax:
    content: placeholder(shape=None, dynamic_axes=None, name='')
    parameters:
    - description: 'the shape of the variable tensor

        '
      id: shape
      type:
      - tuple
      - int
    - description: 'the list of dynamic axes that the actual variable uses

        '
      id: dynamic_axes
      type:
      - list
    - description: 'the name of the placeholder variable in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.variables.Variable

        '
  type: function
  uid: cntk.ops.placeholder
- example:
  - '

    ```


    >>> C.plus([1, 2, 3], [4, 5, 6]).eval()

    array([ 5.,  7.,  9.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10]).eval()

    array([ 5.,  6.,  7.,  8.,  9.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10], [3, 2, 3, 2, 3], [-13], [+42], ''multi_arg_example'').eval()

    array([ 37.,  37.,  39.,  39.,  41.], dtype=float32)

    ```



    ```


    >>> C.plus([-5, -4, -3, -2, -1], [10], [3, 2, 3, 2, 3]).eval()

    array([  8.,   8.,  10.,  10.,  12.], dtype=float32)

    ```

    '
  fullName: cntk.ops.plus
  langs:
  - python
  module: cntk.ops
  name: plus
  source:
    id: plus
    path: bindings/python/cntk\ops\__init__.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\ops\__init__.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 830
  summary: 'The output of this operation is the sum of the two or more input tensors.
    It supports broadcasting.

    '
  syntax:
    content: plus(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: arg1
    - description: 'right side tensor

        '
      id: arg2
    - &id006
      description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    - *id006
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.plus
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(16, dtype = np.float32), [1, 4, 4])\n\
    >>> x = C.input_variable(img.shape)\n>>> C.pooling(x, C.AVG_POOLING, (2,2), (2,2)).eval({x\
    \ : [img]})\narray([[[[  2.5,   4.5],\n          [ 10.5,  12.5]]]], dtype=float32)\n\
    >>> C.pooling(x, C.MAX_POOLING, (2,2), (2,2)).eval({x : [img]})\narray([[[[  5.,\
    \   7.],\n          [ 13.,  15.]]]], dtype=float32)\n```\n"
  fullName: cntk.ops.pooling
  langs:
  - python
  module: cntk.ops
  name: pooling
  source:
    id: pooling
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 465
  summary: 'The pooling operations compute a new tensor by selecting the maximum or
    average value in the pooling input.

    In the case of average pooling with padding, the average is only over the valid
    region.


    N-dimensional pooling allows to create max or average pooling of any dimensions,
    stride or padding.

    '
  syntax:
    content: pooling(operand, pooling_type, pooling_window_shape, strides=(1,), auto_padding=[False],
      ceil_out_dim=False, include_pad=False, name='')
    parameters:
    - description: 'pooling input

        '
      id: operand
    - description: 'one of @cntk.ops.MAX_POOLING or @cntk.ops.AVG_POOLING

        '
      id: pooling_type
    - description: 'dimensions of the pooling window

        '
      id: pooling_window_shape
    - description: 'strides.

        '
      id: strides
      type:
      - default 1
    - description: 'automatic padding flags for each input dimension.

        '
      id: auto_padding
      type:
      - default [False,]
    - description: 'ceiling while computing output size

        '
      id: ceil_out_dim
      type:
      - default False
    - description: 'include pad while average pooling

        '
      id: include_pad
      type:
      - default False
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.pooling
- example:
  - "\n```\n\n>>> C.pow([1, 2, -2], [3, -2, 3]).eval()\narray([ 1.  ,  0.25, -8. \
    \ ], dtype=float32)\n```\n\n\n```\n\n>>> C.pow([[0.5, 2],[4, 1]], -2).eval()\n\
    array([[ 4.    ,  0.25  ],\n       [ 0.0625,  1.    ]], dtype=float32)\n```\n"
  fullName: cntk.ops.pow
  langs:
  - python
  module: cntk.ops
  name: pow
  source:
    id: pow
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 891
  summary: 'Computes *base* raised to the power of *exponent*. It supports broadcasting.

    This is well defined if *base* is non-negative or *exponent* is an integer.

    Otherwise the result is NaN. The gradient with respect to the base is  well

    defined if the forward operation is well defined. The gradient with respect

    to the exponent is well defined if the base is non-negative, and it is set

    to 0 otherwise.

    '
  syntax:
    content: pow(base, exponent, name='')
    parameters:
    - description: 'base tensor

        '
      id: base
    - description: 'exponent tensor

        '
      id: exponent
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.pow
- fullName: cntk.ops.random_sample
  langs:
  - python
  module: cntk.ops
  name: random_sample
  source:
    id: random_sample
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3288
  summary: 'Estimates inclusion frequencies for random sampling with or without

    replacement.


    The output value is a set of num_samples random samples represented

    by a (sparse) matrix of shape [num_samples x len(weights)],

    where len(weights) is the number of classes (categories) to choose

    from. The output has no dynamic axis.

    The samples are drawn according to the weight vector p(i) =

    weights[i] / sum(weights)

    We get one set of samples per minibatch.

    Intended use cases are e.g. sampled softmax, noise contrastive

    estimation etc.

    '
  syntax:
    content: random_sample(weights, num_samples, allow_duplicates, seed=4294967293,
      name='')
    parameters:
    - description: 'input vector of sampling weights which should be

        non-negative numbers.

        '
      id: weights
    - description: 'number of expected samples

        '
      id: num_samples
      type:
      - int
    - description: 'If sampling is done

        with replacement (*True*) or without (*False*).

        '
      id: allow_duplicates
      type:
      - bool
    - description: 'random seed.

        '
      id: seed
      type:
      - int
    - description: 'the name of the Function instance in the network.

        '
      id: name
      type:
      - cntk.ops.str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.random_sample
- example:
  - '

    ```


    >>> import numpy as np

    >>> from cntk import *

    >>> # weight vector with 100 ''1000''-values followed

    >>> # by 100 ''1'' values

    >>> w1 = np.full((100),1000, dtype = np.float)

    >>> w2 = np.full((100),1, dtype = np.float)

    >>> w = np.concatenate((w1, w2))

    >>> f = random_sample_inclusion_frequency(w, 150, True).eval()

    >>> f[0]

    1.4985015

    >>> f[1]

    1.4985015

    >>> f[110]

    0.0014985015

    >>> # when switching to sampling without duplicates samples are

    >>> # forced to pick the low weight classes too

    >>> f = random_sample_inclusion_frequency(w, 150, False).eval()

    >>> f[0]

    1.0

    ```

    '
  fullName: cntk.ops.random_sample_inclusion_frequency
  langs:
  - python
  module: cntk.ops
  name: random_sample_inclusion_frequency
  source:
    id: random_sample_inclusion_frequency
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3328
  summary: 'For weighted sampling with the specified sample size (*num_samples*)

    this operation computes the expected number of occurrences of each class

    in the sampled set. In case of sampling without replacement

    the result is only an estimate which might be quite rough in the

    case of small sample sizes.

    Intended uses are e.g. sampled softmax, noise contrastive

    estimation etc.

    This operation will be typically used together

    with @cntk.ops.random_sample.

    '
  syntax:
    content: random_sample_inclusion_frequency(weights, num_samples, allow_duplicates,
      seed=4294967293, name='')
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.random_sample_inclusion_frequency
- example:
  - '

    ```


    >>> C.reciprocal([-1/3, 1/5, -2, 3]).eval()

    array([-3.      ,  5.      , -0.5     ,  0.333333], dtype=float32)

    ```

    '
  fullName: cntk.ops.reciprocal
  langs:
  - python
  module: cntk.ops
  name: reciprocal
  source:
    id: reciprocal
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2110
  summary: 'Computes the element-wise reciprocal of `x`:

    '
  syntax:
    content: reciprocal(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reciprocal
- fullName: cntk.ops.reconcile_dynamic_axes
  langs:
  - python
  module: cntk.ops
  name: reconcile_dynamic_axes
  source:
    id: reconcile_dynamic_axes
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 219
  summary: "   Create a new Function instance which reconciles the dynamic axes of\
    \ the\n   specified tensor operands. The output of the returned Function has the\
    \ sample\n   layout of the 'x' operand and the dynamic axes of the 'dynamic_axes_as'\
    \ operand.\n   This operator also performs a runtime check to ensure that the\
    \ dynamic axes layouts\n   of the 2 operands indeed match.\n"
  syntax:
    content: reconcile_dynamic_axes(x, dynamic_axes_as, name='')
    parameters:
    - description: 'The Function/Variable, whose dynamic axes are to be reconciled

        '
      id: x
    - description: 'The Function/Variable, to whose dynamic axes the

        operand ''x''''s dynamic axes are reconciled to.

        '
      id: dynamic_axes_as
    - description: 'the name of the reconcile_dynamic_axes Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reconcile_dynamic_axes
- example:
  - "\n```\n\n>>> C.reduce_l1([[[1,2], [3,4]],[[5,6], [7,8]],[[9,10], [11,12]]], 2,\
    \ False).eval()\narray([[  3.,   7.],\n       [ 11.,  15.],\n       [ 19.,  23.]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_l1
  langs:
  - python
  module: cntk.ops
  name: reduce_l1
  source:
    id: reduce_l1
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3062
  summary: 'Computes the L1 norm of the input tensor''s element along the provided
    axes.

    The resulted tensor has the same rank as the input if keepdims equal 1.

    If keepdims equal 0, then the resulted tensor have the reduced dimension pruned.

    '
  syntax:
    content: reduce_l1(x, axis=None, keepdims=True, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_l1
- example:
  - "\n```\n\n>>> C.reduce_l2([[[1,2], [3,4]]], 2).eval()\narray([[[ 2.236068],\n\
    \        [ 5.        ]]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_l2
  langs:
  - python
  module: cntk.ops
  name: reduce_l2
  source:
    id: reduce_l2
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3088
  summary: 'Computes the L2 norm of the input tensor''s element along the provided
    axes.

    The resulted tensor has the same rank as the input if keepdims equal 1.

    If keepdims equal 0, then the resulted tensor have the reduced dimension pruned.

    '
  syntax:
    content: reduce_l2(x, axis=None, keepdims=True, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_l2
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_log_sum_exp(data, axis=0).eval().round(4)\n\
    array([[[ 55.      ,   2.0986],\n        [ 60.      ,   3.0986]]], dtype=float32)\n\
    >>> np.log(np.sum(np.exp(data), axis=0)).round(4)\narray([[ 55.      ,   2.0986],\n\
    \       [ 60.      ,   3.0986]], dtype=float32)\n>>> C.reduce_log_sum_exp(data,\
    \ axis=(0,2)).eval().round(4)\narray([[[ 55.],\n        [ 60.]]], dtype=float32)\n\
    >>> np.log(np.sum(np.exp(data), axis=(0,2))).round(4)\narray([ 55.,  60.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> x = C.input_variable(shape=(2,2))\n>>> lse = C.reduce_log_sum_exp(x,\
    \ axis=[C.axis.Axis.default_batch_axis(), 1])\n>>> lse.eval({x:data}).round(4)\n\
    array([[ 55.],\n       [ 60.]], dtype=float32)\n>>> np.log(np.sum(np.exp(data),\
    \ axis=(0,2))).round(4)\narray([ 55.,  60.], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_log_sum_exp
  langs:
  - python
  module: cntk.ops
  name: reduce_log_sum_exp
  source:
    id: reduce_log_sum_exp
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2837
  summary: 'Computes the log of the sum of the exponentiations of the input tensor''s

    elements across a specified axis or a list of specified axes.


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_log_sum_exp(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_log_sum_exp
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_max(data, 0).eval().round(4)\n\
    array([[[ 55.,   1.],\n        [ 60.,   2.]]], dtype=float32)\n>>> C.reduce_max(data,\
    \ 1).eval().round(4)\narray([[[ 20.,   2.]],\n<BLANKLINE>\n       [[ 40.,   2.]],\n\
    <BLANKLINE>\n       [[ 60.,   2.]]], dtype=float32)\n>>> C.reduce_max(data, (0,2)).eval().round(4)\n\
    array([[[ 55.],\n        [ 60.]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_max( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[ 55.],\n       [ 60.]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_max
  langs:
  - python
  module: cntk.ops
  name: reduce_max
  source:
    id: reduce_max
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2934
  summary: 'Computes the max of the input tensor''s elements across a specified axis
    or a list of specified axes.


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_max(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_max
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_mean(data, 0).eval().round(4)\n\
    array([[[ 30.,   1.],\n        [ 40.,   2.]]], dtype=float32)\n>>> np.mean(data,\
    \ axis=0).round(4)\narray([[ 30.,   1.],\n       [ 40.,   2.]], dtype=float32)\n\
    >>> C.reduce_mean(data, 1).eval().round(4)\narray([[[ 12.5,   1.5]],\n<BLANKLINE>\n\
    \       [[ 35. ,   1.5]],\n<BLANKLINE>\n       [[ 57.5,   1.5]]], dtype=float32)\n\
    >>> np.mean(data, axis=1).round(4)\narray([[ 12.5,   1.5],\n       [ 35. ,   1.5],\n\
    \       [ 57.5,   1.5]], dtype=float32)\n>>> C.reduce_mean(data, (0,2)).eval().round(4)\n\
    array([[[ 15.5],\n        [ 21. ]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_mean( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[ 15.5],\n       [ 21.      ]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_mean
  langs:
  - python
  module: cntk.ops
  name: reduce_mean
  source:
    id: reduce_mean
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2884
  summary: 'Computes the mean of the input tensor''s elements across a specified axis
    or a list of specified axes.

    '
  syntax:
    content: reduce_mean(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function


        Note that CNTK keeps the shape of the resulting tensors when reducing over
        multiple static axes.

        '
  type: function
  uid: cntk.ops.reduce_mean
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_min(data, 0).eval().round(4)\n\
    array([[[  5.,   1.],\n        [ 20.,   2.]]], dtype=float32)\n>>> C.reduce_min(data,\
    \ 1).eval().round(4)\narray([[[  5.,   1.]],\n<BLANKLINE>\n       [[ 30.,   1.]],\n\
    <BLANKLINE>\n       [[ 55.,   1.]]], dtype=float32)\n>>> C.reduce_min(data, (0,2)).eval().round(4)\n\
    array([[[ 1.],\n        [ 2.]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_min( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[ 1.],\n       [ 2.]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_min
  langs:
  - python
  module: cntk.ops
  name: reduce_min
  source:
    id: reduce_min
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2977
  summary: 'Computes the min of the input tensor''s elements across a specified axis
    or a list of specified axes.

    '
  syntax:
    content: reduce_min(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list of integers
      - a list of cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function


        Note that CNTK keeps the shape of the resulting tensors when reducing over
        multiple static axes.

        '
  type: function
  uid: cntk.ops.reduce_min
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_prod(data, 0).eval().round(4)\n\
    array([[[  8250.,      1.],\n        [ 48000.,      8.]]], dtype=float32)\n>>>\
    \ C.reduce_prod(data, 1).eval().round(4)\narray([[[  100.,     2.]],\n<BLANKLINE>\n\
    \       [[ 1200.,     2.]],\n<BLANKLINE>\n       [[ 3300.,     2.]]], dtype=float32)\n\
    >>> C.reduce_prod(data, (0,2)).eval().round(4)\narray([[[   8250.],\n        [\
    \ 384000.]]], dtype=float32)\n```\n\n\n```\n\n>>> x = C.input_variable((2,2))\n\
    >>> C.reduce_prod( x * 1.0, (C.Axis.default_batch_axis(), 1)).eval({x: data}).round(4)\n\
    array([[   8250.],\n       [ 384000.]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_prod
  langs:
  - python
  module: cntk.ops
  name: reduce_prod
  source:
    id: reduce_prod
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3020
  summary: 'Computes the min of the input tensor''s elements across the specified
    axis.


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_prod(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_prod
- example:
  - "\n```\n\n>>> # create 3x2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data = np.array([[[5,1], [20,2]],[[30,1], [40,2]],[[55,1], [60,2]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> C.reduce_sum(data, 0).eval().round(4)\n\
    array([[[  90.,    3.],\n        [ 120.,    6.]]], dtype=float32)\n>>> np.sum(data,\
    \ axis=0).round(4)\narray([[  90.,    3.],\n       [ 120.,    6.]], dtype=float32)\n\
    >>> C.reduce_sum(data, 1).eval().round(4)\narray([[[  25.,    3.]],\n<BLANKLINE>\n\
    \       [[  70.,    3.]],\n<BLANKLINE>\n       [[ 115.,    3.]]], dtype=float32)\n\
    >>> np.sum(data, axis=1).round(4)\narray([[  25.,    3.],\n       [  70.,    3.],\n\
    \       [ 115.,    3.]], dtype=float32)\n>>> C.reduce_sum(data, (0,2)).eval().round(4)\n\
    array([[[  93.],\n        [ 126.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_sum
  langs:
  - python
  module: cntk.ops
  name: reduce_sum
  source:
    id: reduce_sum
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2787
  summary: 'Computes the sum of the input tensor''s elements across one axis or a
    list of axes. If the axis parameter

    is not specified then the sum will be computed over all static axes, which is

    equivalent with specifying `axis=Axis.all_static_axes()`. If

    `axis=Axis.all_axes()` is specified, then the output is a scalar which is the
    sum of all the

    elements in the minibatch. And if `axis=Axis.default_batch_axis()` is specified,
    then the reduction

    will happen across the batch axis (In this case the input must not be a sequence).


    Note that CNTK keeps the shape of the resulting tensors when reducing over multiple
    static axes.

    '
  syntax:
    content: reduce_sum(x, axis=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_sum
- example:
  - "\n```\n\n>>> C.reduce_sum_square([[[1,2], [3,4]]], 2).eval()\narray([[[  5.],\n\
    \        [ 25.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.reduce_sum_square
  langs:
  - python
  module: cntk.ops
  name: reduce_sum_square
  source:
    id: reduce_sum_square
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3113
  summary: 'Computes the sum square of the input tensor''s element along the provided
    axes.

    The resulted tensor has the same rank as the input if keepdims equal 1.

    If keepdims equal 0, then the resulted tensor have the reduced dimension pruned.

    '
  syntax:
    content: reduce_sum_square(x, axis=None, keepdims=True, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'axis along which the reduction will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
      - a list
      - tuple of int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reduce_sum_square
- example:
  - '

    ```


    >>> C.relu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[ 0.,  0.,  0.,  1.,  2.]], dtype=float32)

    ```

    '
  fullName: cntk.ops.relu
  langs:
  - python
  module: cntk.ops
  name: relu
  source:
    id: relu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1342
  summary: 'Rectified linear operation. Computes the element-wise rectified linear

    of `x`: `max(x, 0)`


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: relu(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.relu
- example:
  - "\n```\n\n>>> i1 = C.input_variable(shape=(3,2))\n>>> C.reshape(i1, (2,3)).eval({i1:np.asarray([[[[0.,\
    \ 1.],[2., 3.],[4., 5.]]]], dtype=np.float32)})\narray([[[ 0.,  1.,  2.],\n  \
    \       [ 3.,  4.,  5.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.reshape
  langs:
  - python
  module: cntk.ops
  name: reshape
  source:
    id: reshape
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2272
  summary: 'Reinterpret input samples as having different tensor dimensions

    One dimension may be specified as 0 and will be inferred


    The output tensor has the shape specified by ''shape''.

    '
  syntax:
    content: reshape(x, shape, begin_axis=None, end_axis=None, name='')
    parameters:
    - description: 'tensor to be reshaped

        '
      id: x
    - description: 'a tuple defining the resulting shape. The specified shape tuple

        may contain -1 for at most one axis, which is automatically inferred to the

        correct dimension size by dividing the total size of the sub-shape being reshaped

        with the product of the dimensions of all the non-inferred axes of the replacement

        shape.

        '
      id: shape
      type:
      - tuple
    - description: 'shape replacement begins at this axis. Negative values

        are counting from the end. *None* is the same as 0. To refer to the end of
        the shape tuple,

        pass *Axis.new_leading_axis()*.

        '
      id: begin_axis
      type:
      - int
      - None
    - description: 'shape replacement ends at this axis (excluding this axis).

        Negative values are counting from the end. *None* refers to the end of the
        shape tuple.

        '
      id: end_axis
      type:
      - int
      - None
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.reshape
- fullName: cntk.ops.roipooling
  langs:
  - python
  module: cntk.ops
  name: roipooling
  source:
    id: roipooling
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 431
  summary: 'The ROI (Region of Interest) pooling operation pools over sub-regions
    of an input volume and produces

    a fixed sized output volume regardless of the ROI size. It is used for example
    for object detection.


    Each input image has a fixed number of regions of interest, which are specified
    as bounding boxes (x, y, w, h)

    that are relative to the image size [W x H]. This operation can be used as a replacement
    for the final

    pooling layer of an image classification network (as presented in Fast R-CNN and
    others).


    Changed in version 2.1: The signature was updated to match the Caffe implementation:

    the parameters *pooling_type* and *spatial_scale* were added, and

    the coordinates for the parameters *rois* are now absolute to the original image
    size.

    '
  syntax:
    content: roipooling(operand, rois, pooling_type, roi_output_shape, spatial_scale,
      name='')
    parameters:
    - description: 'a convolutional feature map as the input volume ([W x H x C x
        N]).

        '
      id: operand
    - description: 'only @cntk.ops.MAX_POOLING

        '
      id: pooling_type
    - description: 'the coordinates of the ROIs per image ([4 x roisPerImage x N]),
        each ROI is (x1, y1, x2, y2) absolute to original image size.

        '
      id: rois
    - description: 'dimensions (width x height) of the ROI pooling output shape

        '
      id: roi_output_shape
    - description: 'the scale of operand from the original image size.

        '
      id: spatial_scale
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.roipooling
- example:
  - "\n```\n\n>>> C.round([0.2, 1.3, 4., 5.5, 0.0]).eval()\narray([ 0.,  1.,  4.,\
    \  6.,  0.], dtype=float32)\n```\n\n\n```\n\n>>> C.round([[0.6, 3.3], [1.9, 5.6]]).eval()\n\
    array([[ 1.,  3.],\n       [ 2.,  6.]], dtype=float32)\n```\n\n\n```\n\n>>> C.round([-5.5,\
    \ -4.2, -3., -0.7, 0]).eval()\narray([-5., -4., -3., -1.,  0.], dtype=float32)\n\
    ```\n\n\n```\n\n>>> C.round([[-0.6, -4.3], [1.9, -3.2]]).eval()\narray([[-1.,\
    \ -4.],\n       [ 2., -3.]], dtype=float32)\n```\n"
  fullName: cntk.ops.round
  langs:
  - python
  module: cntk.ops
  name: round
  source:
    id: round
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1270
  summary: 'The output of this operation is the element wise value rounded to the
    nearest integer.

    In case of tie, where element can have exact fractional part of 0.5

    this operation follows "round half-up" tie breaking strategy.

    This is different from the round operation of numpy which follows

    round half to even.

    '
  syntax:
    content: round(arg, name='')
    parameters:
    - description: 'input tensor

        '
      id: arg
    - description: 'the name of the Function instance in the network (optional)

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.round
- example:
  - '

    ```


    >>> C.selu([[-1, -0.5, 0, 1, 2]]).eval()

    array([[-1.111331, -0.691758,  0.      ,  1.050701,  2.101402]], dtype=float32)

    ```

    '
  fullName: cntk.ops.selu
  langs:
  - python
  module: cntk.ops
  name: selu
  source:
    id: selu
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1389
  summary: 'Scaled exponential linear unit operation. Computes the element-wise exponential
    linear

    of `x`: `scale * x` for `x >= 0` and `x`: `scale * alpha * (exp(x)-1)` otherwise.


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: selu(x, scale=1.0507009873554805, alpha=1.6732632423543772, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.selu
- example:
  - '

    ```


    >>> C.sigmoid([-2, -1., 0., 1., 2.]).eval()

    array([ 0.119203,  0.268941,  0.5     ,  0.731059,  0.880797], dtype=float32)

    ```

    '
  fullName: cntk.ops.sigmoid
  langs:
  - python
  module: cntk.ops
  name: sigmoid
  source:
    id: sigmoid
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1525
  summary: 'Computes the element-wise sigmoid of `x`:



    The output tensor has the same shape as `x`.

    '
  syntax:
    content: sigmoid(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sigmoid
- example:
  - "\n```\n\n>>> np.round(C.sin(np.arcsin([[1,0.5],[-0.25,-0.75]])).eval(),5)\narray([[\
    \ 1.  ,  0.5 ],\n       [-0.25, -0.75]], dtype=float32)\n```\n"
  fullName: cntk.ops.sin
  langs:
  - python
  module: cntk.ops
  name: sin
  source:
    id: sin
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1593
  summary: 'Computes the element-wise sine of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: sin(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sin
- example:
  - "\n```\n\n>>> np.round(C.sinh([[1,0.5],[-0.25,-0.75]]).eval(),5)\narray([[ 1.1752\
    \ ,  0.5211 ],\n       [-0.25261, -0.82232]], dtype=float32)\n```\n"
  fullName: cntk.ops.sinh
  langs:
  - python
  module: cntk.ops
  name: sinh
  source:
    id: sinh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1681
  summary: 'Computes the element-wise sinh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: sinh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sinh
- example:
  - "\n```\n\n>>> # slice using input variable\n>>> # create 2x3 matrix\n>>> x1 =\
    \ C.input_variable((2,3))\n>>> # slice index 1 (second) at first axis\n>>> C.slice(x1,\
    \ 0, 1, 2).eval({x1: np.asarray([[[1,2,-3],\n...                             \
    \                [4, 5, 6]]],dtype=np.float32)})\narray([[[ 4.,  5.,  6.]]], dtype=float32)\n\
    <BLANKLINE>\n>>> # slice index 0 (first) at second axis\n>>> C.slice(x1, 1, 0,\
    \ 1).eval({x1: np.asarray([[[1,2,-3],\n...                                   \
    \          [4, 5, 6]]],dtype=np.float32)})\narray([[[ 1.],\n        [ 4.]]], dtype=float32)\n\
    >>> # slice with strides\n>>> C.slice(x1, 0, 0, 2, 2).eval({x1: np.asarray([[[1,2,-3],\n\
    ...                                                [4, 5, 6]]],dtype=np.float32)})\n\
    array([[[ 1.,  2., -3.]]], dtype=float32)\n<BLANKLINE>\n>>> # reverse\n>>> C.slice(x1,\
    \ 0, 0, 2, -1).eval({x1: np.asarray([[[1,2,-3],\n...                         \
    \                        [4, 5, 6]]],dtype=np.float32)})\narray([[[ 4.,  5., \
    \ 6.],\n[ 1.,  2., -3.]]], dtype=float32)\n<BLANKLINE>\n>>> # slice along multiple\
    \ axes\n>>> C.slice(x1, [0,1], [1,0], [2,1]).eval({x1: np.asarray([[[1, 2, -3],\n\
    ...                                                         [4, 5, 6]]],dtype=np.float32)})\n\
    array([[[ 4.]]], dtype=float32)\n<BLANKLINE>\n>>> # slice using constant\n>>>\
    \ data = np.asarray([[1, 2, -3],\n...                    [4, 5,  6]], dtype=np.float32)\n\
    >>> x = C.constant(value=data)\n>>> C.slice(x, 0, 1, 2).eval()\narray([[ 4., \
    \ 5.,  6.]], dtype=float32)\n>>> C.slice(x, 1, 0, 1).eval()\narray([[ 1.],\n \
    \      [ 4.]], dtype=float32)\n>>> C.slice(x, [0,1], [1,0], [2,1]).eval()\narray([[\
    \ 4.]], dtype=float32)\n<BLANKLINE>\n>>> # slice using the index overload\n>>>\
    \ data = np.asarray([[1, 2, -3],\n...                    [4, 5,  6]], dtype=np.float32)\n\
    >>> x = C.constant(value=data)\n>>> x[0].eval()\narray([[ 1.,  2.,  -3.]], dtype=float32)\n\
    >>> x[0, [1,2]].eval()\narray([[ 2.,  -3.]], dtype=float32)\n<BLANKLINE>\n>>>\
    \ x[1].eval()\narray([[ 4.,  5.,  6.]], dtype=float32)\n>>> x[:,:2,:].eval()\n\
    array([[ 1.,  2.],\n       [ 4.,  5.]], dtype=float32)\n```\n"
  fullName: cntk.ops.slice
  langs:
  - python
  module: cntk.ops
  name: slice
  seealsoContent: "See also: Indexing in NumPy: [https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)\
    \ \n"
  source:
    id: slice
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2492
  summary: 'Slice the input along one or multiple axes.

    '
  syntax:
    content: slice(x, axis, begin_index, end_index, strides=None, name='')
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.slice
- example:
  - "\n```\n\n>>> C.softmax([[1, 1, 2, 3]]).eval()\narray([[ 0.082595,  0.082595,\
    \  0.224515,  0.610296]], dtype=float32)\n```\n\n\n```\n\n>>> C.softmax([1, 1]).eval()\n\
    array([ 0.5,  0.5], dtype=float32)\n```\n\n\n```\n\n>>> C.softmax([[[1, 1], [3,\
    \ 5]]], axis=-1).eval()\narray([[[ 0.5     ,  0.5     ],\n        [ 0.119203,\
    \  0.880797]]], dtype=float32)\n```\n\n\n```\n\n>>> C.softmax([[[1, 1], [3, 5]]],\
    \ axis=1).eval()\narray([[[ 0.119203,  0.017986],\n        [ 0.880797,  0.982014]]],\
    \ dtype=float32)\n```\n"
  fullName: cntk.ops.softmax
  langs:
  - python
  module: cntk.ops
  name: softmax
  source:
    id: softmax
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1767
  summary: 'Computes the gradient of  at `z = x`. Concretely,



    with the understanding that the implementation can use equivalent formulas

    for efficiency and numerical stability.


    The output is a vector of non-negative numbers that sum to 1 and can

    therefore be interpreted as probabilities for mutually exclusive outcomes

    as in the case of multiclass classification.


    If `axis` is given as integer, then the softmax will be computed along that axis.

    If the provided `axis` is -1, it will be computed along the last axis. Otherwise,

    softmax will be applied to all axes.

    '
  syntax:
    content: softmax(x, axis=None, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'axis along which the softmax operation will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.softmax
- example:
  - '

    ```


    >>> C.softplus([[-1, -0.5, 0, 1, 2]]).eval()

    array([[ 0.313262,  0.474077,  0.693147,  1.313262,  2.126928]], dtype=float32)

    ```



    ```


    >>> C.softplus([[-1, -0.5, 0, 1, 2]], steepness=4).eval()

    array([[ 0.004537,  0.031732,  0.173287,  1.004537,  2.000084]], dtype=float32)

    ```

    '
  fullName: cntk.ops.softplus
  langs:
  - python
  module: cntk.ops
  name: softplus
  source:
    id: softplus
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1466
  summary: 'Softplus operation. Computes the element-wise softplus of `x`:



    The optional `steepness` allows to make the knee sharper (`steepness>1`) or softer,
    by computing

    `softplus(x * steepness) / steepness`.

    (For very large steepness, this approaches a linear rectifier).


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: softplus(x, steepness=1, name='')
    parameters:
    - description: 'any @cntk.ops.functions.Function that outputs a tensor.

        '
      id: x
      type:
      - numpy.array
      - cntk.ops.functions.Function
    - description: 'optional steepness factor

        '
      id: steepness
      type:
      - float, optional
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, default to ''
    return:
      description: 'An instance of @cntk.ops.functions.Function

        '
      type:
      - cntk.ops.functions.Function
  type: function
  uid: cntk.ops.softplus
- example:
  - '

    ```


    >>> C.softsign([[-1, 0, 1]]).eval()

    array([[-0.5,  0. ,  0.5]], dtype=float32)

    ```

    '
  fullName: cntk.ops.softsign
  langs:
  - python
  module: cntk.ops
  name: softsign
  source:
    id: softsign
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1502
  summary: 'Computes the element-wise softsign of `x`:



    The output tensor has the same shape as `x`.

    '
  syntax:
    content: softsign(x, steepness=1, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.softsign
- example:
  - "\n```\n\n>>> np.random.seed(3)\n>>> x = np.random.randint(low=0, high=100, size=(1,\
    \ 4, 6)).astype(np.float32)\n>>> a = C.input_variable((1, 4, 6))\n>>> s2d_op =\
    \ C.space_to_depth(a, block_size=2)\n>>> s2d_op.eval({a:x})\narray([[[[ 24., \
    \ 56.,   0.],\n         [ 96.,  44.,  39.]],\n<BLANKLINE>\n        [[  3.,  72.,\
    \  21.],\n         [ 20.,  93.,  14.]],\n<BLANKLINE>\n        [[ 19.,  41.,  21.],\n\
    \         [ 26.,  90.,  66.]],\n<BLANKLINE>\n        [[ 74.,  10.,  38.],\n  \
    \       [ 81.,  22.,   2.]]]], dtype=float32)\n```\n"
  fullName: cntk.ops.space_to_depth
  langs:
  - python
  module: cntk.ops
  name: space_to_depth
  seealsoContent: "See also: [1] W. Shi et. al. [: Real-Time Single Image and Video\
    \ Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network](https://arxiv.org/abs/1609.05158).\
    \ \n"
  source:
    id: space_to_depth
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3853
  summary: 'Rearranges elements in the input tensor from the spatial dimensions to
    the depth dimension.


    This is the reverse transformation of depth_to_space. This operation is useful
    for implementing

    and testing sub-pixel convolution that is part of models for image super-resolution
    (see [1]).

    It rearranges elements of an input tensor of shape (C, H, W) to a tensor of shape
    (C*b*b, H/b, W/b),

    where b is the *block_size*, by rearranging non-overlapping spatial blocks of
    size *block_size* x *block_size*

    into the depth/channel dimension at each location.

    '
  syntax:
    content: space_to_depth(operand, block_size, name='')
    parameters:
    - description: 'Input tensor, with dimensions .

        '
      id: operand
    - description: 'Integer value. This defines the size of the spatial block whose
        elements

        are moved to the depth dimension. Size of spatial dimensions (H, W) in the
        input tensor

        must be divisible by math:*block_size*

        '
      id: block_size
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.space_to_depth
- example:
  - "\n```\n\n>>> # create 2x2 matrix in a sequence of length 1 in a batch of one\
    \ sample\n>>> data1 = np.asarray([[[1, 2],\n...                      [4, 5]]],\
    \ dtype=np.float32)\n```\n\n\n```\n\n>>> x = C.constant(value=data1)\n>>> # create\
    \ 3x2 matrix in a sequence of length 1 in a batch of one sample\n>>> data2 = np.asarray([[[10,\
    \ 20],\n...                       [30, 40],\n...                       [50, 60]]],dtype=np.float32)\n\
    >>> y = C.constant(value=data2)\n>>> # splice both inputs on axis=0 returns a\
    \ 5x2 matrix\n>>> C.splice(x, y, axis=1).eval()\narray([[[  1.,   2.],\n     \
    \   [  4.,   5.],\n        [ 10.,  20.],\n        [ 30.,  40.],\n        [ 50.,\
    \  60.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.splice
  langs:
  - python
  module: cntk.ops
  name: splice
  source:
    id: splice
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2583
  summary: 'Concatenate the input tensors along an axis.

    '
  syntax:
    content: splice(*inputs, **kw_axis_name)
    parameters:
    - description: 'one or more input tensors

        '
      id: inputs
    - description: 'axis along which the

        concatenation will be performed

        '
      id: axis
      type:
      - int
      - cntk.axis.Axis, optional, keyword only
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional, keyword only
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.splice
- example:
  - '

    ```


    >>> C.sqrt([0., 4.]).eval()

    array([ 0.,  2.], dtype=float32)

    ```

    '
  fullName: cntk.ops.sqrt
  langs:
  - python
  module: cntk.ops
  name: sqrt
  source:
    id: sqrt
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1942
  summary: "Computes the element-wise square-root of `x`:\n\n\nNote: CNTK returns\
    \ zero for sqrt of negative nubmers, this will be changed to return NaN \n"
  syntax:
    content: sqrt(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sqrt
- example:
  - '

    ```


    >>> C.square([1., 10.]).eval()

    array([   1.,  100.], dtype=float32)

    ```

    '
  fullName: cntk.ops.square
  langs:
  - python
  module: cntk.ops
  name: square
  source:
    id: square
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1968
  summary: 'Computes the element-wise square of `x`:

    '
  syntax:
    content: square(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.square
- example:
  - "\n```\n\n>>> x0 = np.arange(12).reshape((2, 2, 1, 3)).astype('f')\n>>> x = C.input_variable((2,\
    \ 1, 3))\n>>> C.squeeze(x).eval({x: x0})\narray([[[  0.,   1.,   2.],\n      \
    \  [  3.,   4.,   5.]],\n<BLANKLINE>\n       [[  6.,   7.,   8.],\n        [ \
    \ 9.,  10.,  11.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.squeeze
  langs:
  - python
  module: cntk.ops
  name: squeeze
  source:
    id: squeeze
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2333
  summary: "   Removes axes whose size is 1. If `axes` is specified, and any of\n\
    \   their size is not 1 an exception will be raised.\n"
  syntax:
    content: squeeze(x, axes=None, name='')
    parameters:
    - description: 'input tensor

        '
      id: x
    - description: 'The axes to squeeze out (default: all static axes).

        '
      id: axes
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.squeeze
- fullName: cntk.ops.stop_gradient
  langs:
  - python
  module: cntk.ops
  name: stop_gradient
  source:
    id: stop_gradient
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3652
  summary: 'Outputs its input as it is and prevents any gradient contribution from
    its output to its input.

    '
  syntax:
    content: stop_gradient(input, name='')
    parameters:
    - description: 'class:*~cntk.ops.functions.Function* that outputs a tensor

        '
      id: input
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.stop_gradient
- example:
  - '

    ```


    >>> in1_data = np.asarray([[1., 2., 3., 4.]], np.float32)

    >>> in2_data = np.asarray([[0., 5., -3., 2.]], np.float32)

    >>> in1 = C.input_variable(np.shape(in1_data))

    >>> in2 = C.input_variable(np.shape(in2_data))

    >>> C.sum([in1, in2]).eval({in1: in1_data, in2: in2_data})

    array([[[ 1.,  7.,  0.,  6.]]], dtype=float32)

    ```

    '
  fullName: cntk.ops.sum
  langs:
  - python
  module: cntk.ops
  name: sum
  source:
    id: sum
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 119
  summary: '   Create a new Function instance that computes element-wise sum of input
    tensors.

    '
  syntax:
    content: sum(*operands, **kw_name)
    parameters:
    - description: 'list of functions

        '
      id: operands
      type:
      - list
    - description: 'the name of the sum Function in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.sum
- example:
  - "\n```\n\n>>> C.swapaxes([[[0,1],[2,3],[4,5]]], 1, 2).eval()\narray([[[ 0.,  2.,\
    \  4.],\n        [ 1.,  3.,  5.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.swapaxes
  langs:
  - python
  module: cntk.ops
  name: swapaxes
  source:
    id: swapaxes
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2423
  summary: 'Swaps two axes of the tensor. The output tensor has the same data but
    with

    `axis1` and `axis2` swapped.

    '
  syntax:
    content: swapaxes(x, axis1=0, axis2=1, name='')
    parameters:
    - description: 'tensor to be transposed

        '
      id: x
    - description: 'the axis to swap with `axis2`

        '
      id: axis1
      type:
      - int
      - cntk.axis.Axis
    - description: 'the axis to swap with `axis1`

        '
      id: axis2
      type:
      - int
      - cntk.axis.Axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.swapaxes
- example:
  - "\n```\n\n>>> C.tanh([[1,2],[3,4]]).eval()\narray([[ 0.761594,  0.964028],\n \
    \      [ 0.995055,  0.999329]], dtype=float32)\n```\n"
  fullName: cntk.ops.tanh
  langs:
  - python
  module: cntk.ops
  name: tanh
  source:
    id: tanh
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1549
  summary: 'Computes the element-wise tanh of `x`:


    The output tensor has the same shape as `x`.

    '
  syntax:
    content: tanh(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.tanh
- example:
  - "\n```\n\n>>> C.times([[1,2],[3,4]], [[5],[6]]).eval()\narray([[ 17.],\n     \
    \  [ 39.]], dtype=float32)\n```\n\n\n```\n\n>>> C.times(1.*np.reshape(np.arange(8),\
    \ (2,2,2)),1.*np.reshape(np.arange(8), (2,2,2)), output_rank=1).eval()\narray([[\
    \ 28.,  34.],\n       [ 76.,  98.]])\n```\n\n\n```\n\n>>> C.times(1.*np.reshape(np.arange(8),\
    \ (2,2,2)),1.*np.reshape(np.arange(8), (2,2,2)), output_rank=2).eval()\narray([[[[\
    \  4.,   5.],\n         [  6.,   7.]],\n<BLANKLINE>\n        [[ 12.,  17.],\n\
    \         [ 22.,  27.]]],\n<BLANKLINE>\n<BLANKLINE>\n       [[[ 20.,  29.],\n\
    \         [ 38.,  47.]],\n<BLANKLINE>\n        [[ 28.,  41.],\n         [ 54.,\
    \  67.]]]])\n```\n"
  fullName: cntk.ops.times
  langs:
  - python
  module: cntk.ops
  name: times
  source:
    id: times
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1053
  summary: "The output of this operation is the matrix product of the two input matrices.\n\
    It supports broadcasting. Sparse is supported in the left operand, if it is a\
    \ matrix.\nThe operator '@' has been overloaded such that in Python 3.5 and later\
    \ X @ W equals times(X, W).\n\nFor better performance on times operation on sequence\
    \ which is followed by sequence.reduce_sum, use\ninfer_input_rank_to_map=TIMES_REDUCE_SEQUENCE_AXIS_WITHOUT_INFERRED_INPUT_RANK,\
    \ i.e. replace following:\n\n<!-- literal_block {\"names\": [], \"xml:space\"\
    : \"preserve\", \"backrefs\": [], \"classes\": [], \"ids\": [], \"dupnames\":\
    \ []} -->\n\n````\n\n   sequence.reduce_sum(times(seq1, seq2))\n   ````\n\nwith:\n\
    \n<!-- literal_block {\"names\": [], \"xml:space\": \"preserve\", \"backrefs\"\
    : [], \"classes\": [], \"ids\": [], \"dupnames\": []} -->\n\n````\n\n   times(seq1,\
    \ seq2, infer_input_rank_to_map=TIMES_REDUCE_SEQUENCE_AXIS_WITHOUT_INFERRED_INPUT_RANK)\n\
    \   ````\n"
  syntax:
    content: times(left, right, output_rank=1, infer_input_rank_to_map=-1, name='')
    parameters:
    - description: 'left side matrix or tensor

        '
      id: left
    - description: 'right side matrix or tensor

        '
      id: right
    - description: 'in case we have tensors as arguments, output_rank represents

        the number of axes to be collapsed in order to transform the tensors

        into matrices, perform the operation and then reshape back (explode the axes)

        '
      id: output_rank
      type:
      - int
    - description: 'meant for internal use only. Always use default value

        '
      id: infer_input_rank_to_map
      type:
      - int
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.times
- example:
  - "\n```\n\n>>> a=np.array([[1,2],[3,4]],dtype=np.float32)\n>>> b=np.array([2,-1],dtype=np.float32)\n\
    >>> c=np.array([[2,-1]],dtype=np.float32)\n>>> d=np.reshape(np.arange(24,dtype=np.float32),(4,3,2))\n\
    >>> print(C.times_transpose(a, a).eval())\n[[  5.  11.]\n [ 11.  25.]]\n>>> print(C.times_transpose(a,\
    \ b).eval())\n[[ 0.]\n [ 2.]]\n>>> print(C.times_transpose(a, c).eval())\n[[ 0.]\n\
    \ [ 2.]]\n>>> print(C.times_transpose(b, a).eval())\n[ 0.  2.]\n>>> print(C.times_transpose(b,\
    \ b).eval())\n[ 5.]\n>>> print(C.times_transpose(b, c).eval())\n[ 5.]\n>>> print(C.times_transpose(c,\
    \ a).eval())\n[[ 0.  2.]]\n>>> print(C.times_transpose(c, b).eval())\n[[ 5.]]\n\
    >>> print(C.times_transpose(c, c).eval())\n[[ 5.]]\n>>> print(C.times_transpose(d,\
    \ a).eval())\n[[[   2.    4.]\n  [   8.   18.]\n  [  14.   32.]]\n<BLANKLINE>\n\
    \ [[  20.   46.]\n  [  26.   60.]\n  [  32.   74.]]\n<BLANKLINE>\n [[  38.   88.]\n\
    \  [  44.  102.]\n  [  50.  116.]]\n<BLANKLINE>\n [[  56.  130.]\n  [  62.  144.]\n\
    \  [  68.  158.]]]\n>>> print(C.times_transpose(d, b).eval())\n[[[ -1.]\n  [ \
    \ 1.]\n  [  3.]]\n<BLANKLINE>\n [[  5.]\n  [  7.]\n  [  9.]]\n<BLANKLINE>\n [[\
    \ 11.]\n  [ 13.]\n  [ 15.]]\n<BLANKLINE>\n [[ 17.]\n  [ 19.]\n  [ 21.]]]\n>>>\
    \ print(C.times_transpose(d, c).eval())\n[[[ -1.]\n  [  1.]\n  [  3.]]\n<BLANKLINE>\n\
    \ [[  5.]\n  [  7.]\n  [  9.]]\n<BLANKLINE>\n [[ 11.]\n  [ 13.]\n  [ 15.]]\n<BLANKLINE>\n\
    \ [[ 17.]\n  [ 19.]\n  [ 21.]]]\n```\n"
  fullName: cntk.ops.times_transpose
  langs:
  - python
  module: cntk.ops
  name: times_transpose
  source:
    id: times_transpose
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1111
  summary: 'The output of this operation is the product of the first (`left`) argument
    with the second (`right`) argument transposed.

    The second (`right`) argument must have a rank of 1 or 2.

    This operation is conceptually computing `np.dot(left, right.T)` except when `right`
    is a vector

    in which case the output is `np.dot(left,np.reshape(right,(1,-1)).T)` (matching
    numpy when `left` is a vector).

    '
  syntax:
    content: times_transpose(left, right, name='')
    parameters:
    - description: 'left side tensor

        '
      id: left
    - description: 'right side matrix or vector

        '
      id: right
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.times_transpose
- example:
  - '

    ```


    >>> data = np.arange(12).reshape((3,2,2))

    >>> x = C.constant(value=data)

    >>> y = C.to_batch(x)

    >>> y.shape

    (2, 2)

    ```

    '
  fullName: cntk.ops.to_batch
  langs:
  - python
  module: cntk.ops
  name: to_batch
  source:
    id: to_batch
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2658
  summary: 'Concatenate the input tensor''s first axis to batch axis.

    '
  syntax:
    content: to_batch(x, name='')
    parameters:
    - description: 'a tensor with dynamic axis

        '
      id: x
    - description: '(str, optional, keyword only): the name of the Function instance
        in the network

        '
      id: name
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.to_batch
- fullName: cntk.ops.to_sequence
  langs:
  - python
  module: cntk.ops
  name: to_sequence
  source:
    id: to_sequence
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3222
  summary: 'This function converts ''x'' to a sequence using the most significant

    static axis [0] as the sequence axis.


    The sequenceLengths input is optional; if unspecified, all sequences are

    assumed to be of the same length; i.e. dimensionality of the most significant

    static axis



    '
  syntax:
    content: to_sequence(x, sequence_lengths=None, sequence_axis_name_prefix='toSequence_',
      name='')
    parameters:
    - description: 'the tensor (or its name) which is converted to a sequence

        '
      id: x
    - description: 'Optional tensor operand representing the sequence lengths.

        if unspecified, all sequences are assumed to be of the same length;

        i.e. dimensionality of the most significant static axis.

        '
      id: sequence_lengths
    - description: 'prefix of the new sequence axis name.

        '
      id: sequence_axis_name_prefix
      type:
      - str, optional
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.to_sequence
- fullName: cntk.ops.to_sequence_like
  langs:
  - python
  module: cntk.ops
  name: to_sequence_like
  source:
    id: to_sequence_like
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 3257
  summary: 'This function converts ''x'' to a sequence using the most significant

    static axis [0] as the sequence axis. The length of the sequences are

    obtained from the ''dynamic_axes_like'' operand.



    '
  syntax:
    content: to_sequence_like(x, dynamic_axes_like, name='')
    parameters:
    - description: 'the tensor (or its name) which is converted to a sequence

        '
      id: x
    - description: 'Tensor operand used to obtain the lengths of

        the generated sequences. The dynamic axes of the generated sequence

        tensor match the dynamic axes of the ''dynamic_axes_like'' operand.

        '
      id: dynamic_axes_like
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.to_sequence_like
- example:
  - '

    ```


    >>> x = C.input_variable(10)

    >>> y = C.top_k(-x * C.log(x), 3)

    >>> x0 = np.arange(10,dtype=np.float32)*0.1

    >>> top = y.eval({x:x0})

    >>> top_values = top[y.outputs[0]]

    >>> top_indices = top[y.outputs[1]]

    >>> top_indices

    array([[ 4.,  3.,  5.]], dtype=float32)

    ```

    '
  fullName: cntk.ops.top_k
  langs:
  - python
  module: cntk.ops
  name: top_k
  source:
    id: top_k
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 1839
  summary: 'Computes the `k` largest values of the input tensor and the corresponding
    indices

    along the specified axis (default the last axis). The returned

    @cntk.ops.functions.Function has two outputs. The first one

    contains the top `k` values in sorted order, and the second one contains

    the corresponding top `k` indices.

    '
  syntax:
    content: top_k(x, k, axis=-1, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'number of top items to return

        '
      id: k
      type:
      - int
    - description: 'axis along which to perform the operation (default: -1)

        '
      id: axis
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.top_k
- example:
  - '

    ```


    >>> a = np.arange(24).reshape(2,3,4).astype(''f'')

    >>> np.array_equal(C.transpose(a, perm=(2, 0, 1)).eval(), np.transpose(a, (2,
    0, 1)))

    True

    ```

    '
  fullName: cntk.ops.transpose
  langs:
  - python
  module: cntk.ops
  name: transpose
  source:
    id: transpose
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2397
  summary: 'Permutes the axes of the tensor. The output has the same data but the
    axes

    are permuted according to `perm`.

    '
  syntax:
    content: transpose(x, perm, name='')
    parameters:
    - description: 'tensor to be transposed

        '
      id: x
    - description: 'the permutation to apply to the axes.

        '
      id: perm
      type:
      - list
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.transpose
- example:
  - "\n```\n\n>>> data = np.arange(12).reshape((3,2,2))\n>>> x = C.input((2,2))\n\
    >>> C.unpack_batch(x).eval({x:data})\narray([[[  0.,   1.],\n        [  2.,  \
    \ 3.]],\n<BLANKLINE>\n       [[  4.,   5.],\n        [  6.,   7.]],\n<BLANKLINE>\n\
    \       [[  8.,   9.],\n        [ 10.,  11.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.unpack_batch
  langs:
  - python
  module: cntk.ops
  name: unpack_batch
  source:
    id: unpack_batch
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2628
  summary: 'Concatenate the input tensor''s last dynamic axis to static axis.

    Only tensors with batch axis are supported now.

    '
  syntax:
    content: unpack_batch(x, name='')
    parameters:
    - description: 'a tensor with dynamic axis

        '
      id: x
    - description: '(str, optional, keyword only): the name of the Function instance
        in the network

        '
      id: name
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.unpack_batch
- example:
  - "\n```\n\n>>> img = np.reshape(np.arange(16, dtype = np.float32), [1, 4, 4])\n\
    >>> x = C.input_variable(img.shape)\n>>> y = C.pooling(x, C.MAX_POOLING, (2,2),\
    \ (2,2))\n>>> C.unpooling(y, x, C.MAX_UNPOOLING, (2,2), (2,2)).eval({x : [img]})\n\
    array([[[[  0.,   0.,   0.,   0.],\n          [  0.,   5.,   0.,   7.],\n    \
    \      [  0.,   0.,   0.,   0.],\n          [  0.,  13.,   0.,  15.]]]], dtype=float32)\n\
    ```\n"
  fullName: cntk.ops.unpooling
  langs:
  - python
  module: cntk.ops
  name: unpooling
  source:
    id: unpooling
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 506
  summary: 'Unpools the `operand` using information from `pooling_input`. Unpooling
    mirrors the operations

    performed by pooling and depends on the values provided to the corresponding pooling
    operation. The output

    should have the same shape as pooling_input. Pooling the result of an unpooling
    operation should

    give back the original input.

    '
  syntax:
    content: unpooling(operand, pooling_input, unpooling_type, unpooling_window_shape,
      strides=(1,), auto_padding=[False], name='')
    parameters:
    - description: 'unpooling input

        '
      id: operand
    - description: 'input to the corresponding pooling operation

        '
      id: pooling_input
    - description: 'only @cntk.ops.MAX_UNPOOLING is supported now

        '
      id: unpooling_type
    - description: 'dimensions of the unpooling window

        '
      id: unpooling_window_shape
    - description: 'strides.

        '
      id: strides
      type:
      - default 1
    - description: 'automatic padding flags for each input dimension.

        '
      id: auto_padding
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.unpooling
- example:
  - "\n```\n\n>>> x0 = np.arange(24).reshape((2, 3, 4)).astype('f')\n>>> x = C.input_variable((3,\
    \ 4))\n>>> C.zeros_like(x).eval({x: x0})\narray([[[ 0.,  0.,  0.,  0.],\n    \
    \    [ 0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.]],\n<BLANKLINE>\n    \
    \   [[ 0.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.],\n        [ 0.,  0.,\
    \  0.,  0.]]], dtype=float32)\n```\n"
  fullName: cntk.ops.zeros_like
  langs:
  - python
  module: cntk.ops
  name: zeros_like
  source:
    id: zeros_like
    path: bindings/python/cntk\internal\swig_helper.py
    remote:
      branch: release/2.5
      path: bindings/python/cntk\internal\swig_helper.py
      repo: https://github.com/Microsoft/CNTK.git
    startLine: 2158
  summary: 'Creates an all-zeros tensor with the same shape and dynamic axes as `x`:

    '
  syntax:
    content: zeros_like(x, name='')
    parameters:
    - description: 'numpy array or any @cntk.ops.functions.Function that outputs a
        tensor

        '
      id: x
    - description: 'the name of the Function instance in the network

        '
      id: name
      type:
      - str, optional
    return:
      description: '@cntk.ops.functions.Function

        '
  type: function
  uid: cntk.ops.zeros_like
references:
- fullName: cntk.ops.abs
  isExternal: false
  name: abs
  parent: cntk.ops
  uid: cntk.ops.abs
- fullName: cntk.ops.acos
  isExternal: false
  name: acos
  parent: cntk.ops
  uid: cntk.ops.acos
- fullName: cntk.ops.alias
  isExternal: false
  name: alias
  parent: cntk.ops
  uid: cntk.ops.alias
- fullName: cntk.ops.argmax
  isExternal: false
  name: argmax
  parent: cntk.ops
  uid: cntk.ops.argmax
- fullName: cntk.ops.argmin
  isExternal: false
  name: argmin
  parent: cntk.ops
  uid: cntk.ops.argmin
- fullName: cntk.ops.as_block
  isExternal: false
  name: as_block
  parent: cntk.ops
  uid: cntk.ops.as_block
- fullName: cntk.ops.as_composite
  isExternal: false
  name: as_composite
  parent: cntk.ops
  uid: cntk.ops.as_composite
- fullName: cntk.ops.asin
  isExternal: false
  name: asin
  parent: cntk.ops
  uid: cntk.ops.asin
- fullName: cntk.ops.asinh
  isExternal: false
  name: asinh
  parent: cntk.ops
  uid: cntk.ops.asinh
- fullName: cntk.ops.assign
  isExternal: false
  name: assign
  parent: cntk.ops
  uid: cntk.ops.assign
- fullName: cntk.ops.associative_multi_arg
  isExternal: false
  name: associative_multi_arg
  parent: cntk.ops
  uid: cntk.ops.associative_multi_arg
- fullName: cntk.ops.atanh
  isExternal: false
  name: atanh
  parent: cntk.ops
  uid: cntk.ops.atanh
- fullName: cntk.ops.batch_normalization
  isExternal: false
  name: batch_normalization
  parent: cntk.ops
  uid: cntk.ops.batch_normalization
- fullName: cntk.ops.cast
  isExternal: false
  name: cast
  parent: cntk.ops
  uid: cntk.ops.cast
- fullName: cntk.ops.ceil
  isExternal: false
  name: ceil
  parent: cntk.ops
  uid: cntk.ops.ceil
- fullName: cntk.ops.clip
  isExternal: false
  name: clip
  parent: cntk.ops
  uid: cntk.ops.clip
- fullName: cntk.ops.combine
  isExternal: false
  name: combine
  parent: cntk.ops
  uid: cntk.ops.combine
- fullName: cntk.ops.constant
  isExternal: false
  name: constant
  parent: cntk.ops
  uid: cntk.ops.constant
- fullName: cntk.ops.convolution
  isExternal: false
  name: convolution
  parent: cntk.ops
  uid: cntk.ops.convolution
- fullName: cntk.ops.convolution_transpose
  isExternal: false
  name: convolution_transpose
  parent: cntk.ops
  uid: cntk.ops.convolution_transpose
- fullName: cntk.ops.cos
  isExternal: false
  name: cos
  parent: cntk.ops
  uid: cntk.ops.cos
- fullName: cntk.ops.cosh
  isExternal: false
  name: cosh
  parent: cntk.ops
  uid: cntk.ops.cosh
- fullName: cntk.ops.crop_automatic
  isExternal: false
  name: crop_automatic
  parent: cntk.ops
  uid: cntk.ops.crop_automatic
- fullName: cntk.ops.crop_automatic_with_ancestors
  isExternal: false
  name: crop_automatic_with_ancestors
  parent: cntk.ops
  uid: cntk.ops.crop_automatic_with_ancestors
- fullName: cntk.ops.crop_manual
  isExternal: false
  name: crop_manual
  parent: cntk.ops
  uid: cntk.ops.crop_manual
- fullName: cntk.ops.depth_to_space
  isExternal: false
  name: depth_to_space
  parent: cntk.ops
  uid: cntk.ops.depth_to_space
- fullName: cntk.ops.dropout
  isExternal: false
  name: dropout
  parent: cntk.ops
  uid: cntk.ops.dropout
- fullName: cntk.ops.element_and
  isExternal: false
  name: element_and
  parent: cntk.ops
  uid: cntk.ops.element_and
- fullName: cntk.ops.element_divide
  isExternal: false
  name: element_divide
  parent: cntk.ops
  uid: cntk.ops.element_divide
- fullName: cntk.ops.element_max
  isExternal: false
  name: element_max
  parent: cntk.ops
  uid: cntk.ops.element_max
- fullName: cntk.ops.element_min
  isExternal: false
  name: element_min
  parent: cntk.ops
  uid: cntk.ops.element_min
- fullName: cntk.ops.element_not
  isExternal: false
  name: element_not
  parent: cntk.ops
  uid: cntk.ops.element_not
- fullName: cntk.ops.element_or
  isExternal: false
  name: element_or
  parent: cntk.ops
  uid: cntk.ops.element_or
- fullName: cntk.ops.element_select
  isExternal: false
  name: element_select
  parent: cntk.ops
  uid: cntk.ops.element_select
- fullName: cntk.ops.element_times
  isExternal: false
  name: element_times
  parent: cntk.ops
  uid: cntk.ops.element_times
- fullName: cntk.ops.element_xor
  isExternal: false
  name: element_xor
  parent: cntk.ops
  uid: cntk.ops.element_xor
- fullName: cntk.ops.elu
  isExternal: false
  name: elu
  parent: cntk.ops
  uid: cntk.ops.elu
- fullName: cntk.ops.equal
  isExternal: false
  name: equal
  parent: cntk.ops
  uid: cntk.ops.equal
- fullName: cntk.ops.exp
  isExternal: false
  name: exp
  parent: cntk.ops
  uid: cntk.ops.exp
- fullName: cntk.ops.expand_dims
  isExternal: false
  name: expand_dims
  parent: cntk.ops
  uid: cntk.ops.expand_dims
- fullName: cntk.ops.flatten
  isExternal: false
  name: flatten
  parent: cntk.ops
  uid: cntk.ops.flatten
- fullName: cntk.ops.floor
  isExternal: false
  name: floor
  parent: cntk.ops
  uid: cntk.ops.floor
- fullName: cntk.ops.forward_backward
  isExternal: false
  name: forward_backward
  parent: cntk.ops
  uid: cntk.ops.forward_backward
- fullName: cntk.ops.gather
  isExternal: false
  name: gather
  parent: cntk.ops
  uid: cntk.ops.gather
- fullName: cntk.ops.greater
  isExternal: false
  name: greater
  parent: cntk.ops
  uid: cntk.ops.greater
- fullName: cntk.ops.greater_equal
  isExternal: false
  name: greater_equal
  parent: cntk.ops
  uid: cntk.ops.greater_equal
- fullName: cntk.ops.hard_sigmoid
  isExternal: false
  name: hard_sigmoid
  parent: cntk.ops
  uid: cntk.ops.hard_sigmoid
- fullName: cntk.ops.hardmax
  isExternal: false
  name: hardmax
  parent: cntk.ops
  uid: cntk.ops.hardmax
- fullName: cntk.ops.image_scaler
  isExternal: false
  name: image_scaler
  parent: cntk.ops
  uid: cntk.ops.image_scaler
- fullName: cntk.ops.input
  isExternal: false
  name: input
  parent: cntk.ops
  uid: cntk.ops.input
- fullName: cntk.ops.input_variable
  isExternal: false
  name: input_variable
  parent: cntk.ops
  uid: cntk.ops.input_variable
- fullName: cntk.ops.labels_to_graph
  isExternal: false
  name: labels_to_graph
  parent: cntk.ops
  uid: cntk.ops.labels_to_graph
- fullName: cntk.ops.leaky_relu
  isExternal: false
  name: leaky_relu
  parent: cntk.ops
  uid: cntk.ops.leaky_relu
- fullName: cntk.ops.less
  isExternal: false
  name: less
  parent: cntk.ops
  uid: cntk.ops.less
- fullName: cntk.ops.less_equal
  isExternal: false
  name: less_equal
  parent: cntk.ops
  uid: cntk.ops.less_equal
- fullName: cntk.ops.local_response_normalization
  isExternal: false
  name: local_response_normalization
  parent: cntk.ops
  uid: cntk.ops.local_response_normalization
- fullName: cntk.ops.log
  isExternal: false
  name: log
  parent: cntk.ops
  uid: cntk.ops.log
- fullName: cntk.ops.log_add_exp
  isExternal: false
  name: log_add_exp
  parent: cntk.ops
  uid: cntk.ops.log_add_exp
- fullName: cntk.ops.log_softmax
  isExternal: false
  name: log_softmax
  parent: cntk.ops
  uid: cntk.ops.log_softmax
- fullName: cntk.ops.mean
  isExternal: false
  name: mean
  parent: cntk.ops
  uid: cntk.ops.mean
- fullName: cntk.ops.mean_variance_normalization
  isExternal: false
  name: mean_variance_normalization
  parent: cntk.ops
  uid: cntk.ops.mean_variance_normalization
- fullName: cntk.ops.minus
  isExternal: false
  name: minus
  parent: cntk.ops
  uid: cntk.ops.minus
- fullName: cntk.ops.negate
  isExternal: false
  name: negate
  parent: cntk.ops
  uid: cntk.ops.negate
- fullName: cntk.ops.not_equal
  isExternal: false
  name: not_equal
  parent: cntk.ops
  uid: cntk.ops.not_equal
- fullName: cntk.ops.one_hot
  isExternal: false
  name: one_hot
  parent: cntk.ops
  uid: cntk.ops.one_hot
- fullName: cntk.ops.ones_like
  isExternal: false
  name: ones_like
  parent: cntk.ops
  uid: cntk.ops.ones_like
- fullName: cntk.ops.optimized_rnnstack
  isExternal: false
  name: optimized_rnnstack
  parent: cntk.ops
  uid: cntk.ops.optimized_rnnstack
- fullName: cntk.ops.output_variable
  isExternal: false
  name: output_variable
  parent: cntk.ops
  uid: cntk.ops.output_variable
- fullName: cntk.ops.pad
  isExternal: false
  name: pad
  parent: cntk.ops
  uid: cntk.ops.pad
- fullName: cntk.ops.param_relu
  isExternal: false
  name: param_relu
  parent: cntk.ops
  uid: cntk.ops.param_relu
- fullName: cntk.ops.parameter
  isExternal: false
  name: parameter
  parent: cntk.ops
  uid: cntk.ops.parameter
- fullName: cntk.ops.per_dim_mean_variance_normalize
  isExternal: false
  name: per_dim_mean_variance_normalize
  parent: cntk.ops
  uid: cntk.ops.per_dim_mean_variance_normalize
- fullName: cntk.ops.placeholder
  isExternal: false
  name: placeholder
  parent: cntk.ops
  uid: cntk.ops.placeholder
- fullName: cntk.ops.plus
  isExternal: false
  name: plus
  parent: cntk.ops
  uid: cntk.ops.plus
- fullName: cntk.ops.pooling
  isExternal: false
  name: pooling
  parent: cntk.ops
  uid: cntk.ops.pooling
- fullName: cntk.ops.pow
  isExternal: false
  name: pow
  parent: cntk.ops
  uid: cntk.ops.pow
- fullName: cntk.ops.random_sample
  isExternal: false
  name: random_sample
  parent: cntk.ops
  uid: cntk.ops.random_sample
- fullName: cntk.ops.random_sample_inclusion_frequency
  isExternal: false
  name: random_sample_inclusion_frequency
  parent: cntk.ops
  uid: cntk.ops.random_sample_inclusion_frequency
- fullName: cntk.ops.reciprocal
  isExternal: false
  name: reciprocal
  parent: cntk.ops
  uid: cntk.ops.reciprocal
- fullName: cntk.ops.reconcile_dynamic_axes
  isExternal: false
  name: reconcile_dynamic_axes
  parent: cntk.ops
  uid: cntk.ops.reconcile_dynamic_axes
- fullName: cntk.ops.reduce_l1
  isExternal: false
  name: reduce_l1
  parent: cntk.ops
  uid: cntk.ops.reduce_l1
- fullName: cntk.ops.reduce_l2
  isExternal: false
  name: reduce_l2
  parent: cntk.ops
  uid: cntk.ops.reduce_l2
- fullName: cntk.ops.reduce_log_sum_exp
  isExternal: false
  name: reduce_log_sum_exp
  parent: cntk.ops
  uid: cntk.ops.reduce_log_sum_exp
- fullName: cntk.ops.reduce_max
  isExternal: false
  name: reduce_max
  parent: cntk.ops
  uid: cntk.ops.reduce_max
- fullName: cntk.ops.reduce_mean
  isExternal: false
  name: reduce_mean
  parent: cntk.ops
  uid: cntk.ops.reduce_mean
- fullName: cntk.ops.reduce_min
  isExternal: false
  name: reduce_min
  parent: cntk.ops
  uid: cntk.ops.reduce_min
- fullName: cntk.ops.reduce_prod
  isExternal: false
  name: reduce_prod
  parent: cntk.ops
  uid: cntk.ops.reduce_prod
- fullName: cntk.ops.reduce_sum
  isExternal: false
  name: reduce_sum
  parent: cntk.ops
  uid: cntk.ops.reduce_sum
- fullName: cntk.ops.reduce_sum_square
  isExternal: false
  name: reduce_sum_square
  parent: cntk.ops
  uid: cntk.ops.reduce_sum_square
- fullName: cntk.ops.relu
  isExternal: false
  name: relu
  parent: cntk.ops
  uid: cntk.ops.relu
- fullName: cntk.ops.reshape
  isExternal: false
  name: reshape
  parent: cntk.ops
  uid: cntk.ops.reshape
- fullName: cntk.ops.roipooling
  isExternal: false
  name: roipooling
  parent: cntk.ops
  uid: cntk.ops.roipooling
- fullName: cntk.ops.round
  isExternal: false
  name: round
  parent: cntk.ops
  uid: cntk.ops.round
- fullName: cntk.ops.selu
  isExternal: false
  name: selu
  parent: cntk.ops
  uid: cntk.ops.selu
- fullName: cntk.ops.sigmoid
  isExternal: false
  name: sigmoid
  parent: cntk.ops
  uid: cntk.ops.sigmoid
- fullName: cntk.ops.sin
  isExternal: false
  name: sin
  parent: cntk.ops
  uid: cntk.ops.sin
- fullName: cntk.ops.sinh
  isExternal: false
  name: sinh
  parent: cntk.ops
  uid: cntk.ops.sinh
- fullName: cntk.ops.slice
  isExternal: false
  name: slice
  parent: cntk.ops
  uid: cntk.ops.slice
- fullName: cntk.ops.softmax
  isExternal: false
  name: softmax
  parent: cntk.ops
  uid: cntk.ops.softmax
- fullName: cntk.ops.softplus
  isExternal: false
  name: softplus
  parent: cntk.ops
  uid: cntk.ops.softplus
- fullName: cntk.ops.softsign
  isExternal: false
  name: softsign
  parent: cntk.ops
  uid: cntk.ops.softsign
- fullName: cntk.ops.space_to_depth
  isExternal: false
  name: space_to_depth
  parent: cntk.ops
  uid: cntk.ops.space_to_depth
- fullName: cntk.ops.splice
  isExternal: false
  name: splice
  parent: cntk.ops
  uid: cntk.ops.splice
- fullName: cntk.ops.sqrt
  isExternal: false
  name: sqrt
  parent: cntk.ops
  uid: cntk.ops.sqrt
- fullName: cntk.ops.square
  isExternal: false
  name: square
  parent: cntk.ops
  uid: cntk.ops.square
- fullName: cntk.ops.squeeze
  isExternal: false
  name: squeeze
  parent: cntk.ops
  uid: cntk.ops.squeeze
- fullName: cntk.ops.stop_gradient
  isExternal: false
  name: stop_gradient
  parent: cntk.ops
  uid: cntk.ops.stop_gradient
- fullName: cntk.ops.sum
  isExternal: false
  name: sum
  parent: cntk.ops
  uid: cntk.ops.sum
- fullName: cntk.ops.swapaxes
  isExternal: false
  name: swapaxes
  parent: cntk.ops
  uid: cntk.ops.swapaxes
- fullName: cntk.ops.tanh
  isExternal: false
  name: tanh
  parent: cntk.ops
  uid: cntk.ops.tanh
- fullName: cntk.ops.times
  isExternal: false
  name: times
  parent: cntk.ops
  uid: cntk.ops.times
- fullName: cntk.ops.times_transpose
  isExternal: false
  name: times_transpose
  parent: cntk.ops
  uid: cntk.ops.times_transpose
- fullName: cntk.ops.to_batch
  isExternal: false
  name: to_batch
  parent: cntk.ops
  uid: cntk.ops.to_batch
- fullName: cntk.ops.to_sequence
  isExternal: false
  name: to_sequence
  parent: cntk.ops
  uid: cntk.ops.to_sequence
- fullName: cntk.ops.to_sequence_like
  isExternal: false
  name: to_sequence_like
  parent: cntk.ops
  uid: cntk.ops.to_sequence_like
- fullName: cntk.ops.top_k
  isExternal: false
  name: top_k
  parent: cntk.ops
  uid: cntk.ops.top_k
- fullName: cntk.ops.transpose
  isExternal: false
  name: transpose
  parent: cntk.ops
  uid: cntk.ops.transpose
- fullName: cntk.ops.unpack_batch
  isExternal: false
  name: unpack_batch
  parent: cntk.ops
  uid: cntk.ops.unpack_batch
- fullName: cntk.ops.unpooling
  isExternal: false
  name: unpooling
  parent: cntk.ops
  uid: cntk.ops.unpooling
- fullName: cntk.ops.zeros_like
  isExternal: false
  name: zeros_like
  parent: cntk.ops
  uid: cntk.ops.zeros_like
- fullName: cntk.ops.functions
  isExternal: false
  name: functions
  parent: cntk.ops
  uid: cntk.ops.functions
- fullName: cntk.ops.sequence
  isExternal: false
  name: sequence
  parent: cntk.ops
  uid: cntk.ops.sequence
- fullName: str, optional
  name: str, optional
  spec.python:
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: str, optional
- fullName: str, default to ''
  name: str, default to ''
  spec.python:
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: default to ''
    name: default to ''
    uid: default to ''
  uid: str, default to ''
- fullName: float, default 5000
  name: float, default 5000
  spec.python:
  - fullName: float
    name: float
    uid: float
  - fullName: ', '
    name: ', '
  - fullName: default 5000
    name: default 5000
    uid: default 5000
  uid: float, default 5000
- fullName: float, default 0
  name: float, default 0
  spec.python:
  - fullName: float
    name: float
    uid: float
  - fullName: ', '
    name: ', '
  - fullName: default 0
    name: default 0
    uid: default 0
  uid: float, default 0
- fullName: bool, default True
  name: bool, default True
  spec.python:
  - fullName: bool
    name: bool
    uid: bool
  - fullName: ', '
    name: ', '
  - fullName: default True
    name: default True
    uid: default True
  uid: bool, default True
- fullName: bool, default False
  name: bool, default False
  spec.python:
  - fullName: bool
    name: bool
    uid: bool
  - fullName: ', '
    name: ', '
  - fullName: default False
    name: default False
    uid: default False
  uid: bool, default False
- fullName: NumPy array, optional
  name: NumPy array, optional
  spec.python:
  - fullName: NumPy array
    name: NumPy array
    uid: NumPy array
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: NumPy array, optional
- fullName: int, optional
  name: int, optional
  spec.python:
  - fullName: int
    name: int
    uid: int
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: int, optional
- fullName: tuple, optional
  name: tuple, optional
  spec.python:
  - fullName: tuple
    name: tuple
    uid: tuple
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: tuple, optional
- fullName: int, default 1
  name: int, default 1
  spec.python:
  - fullName: int
    name: int
    uid: int
  - fullName: ', '
    name: ', '
  - fullName: default 1
    name: default 1
    uid: default 1
  uid: int, default 1
- fullName: int, default 1
  name: int, default 1
  spec.python:
  - fullName: int
    name: int
    uid: int
  - fullName: ', '
    name: ', '
  - fullName: default 1
    name: default 1
    uid: default 1
  uid: int, default 1
- fullName: float, [0,1)
  name: float, [0,1)
  spec.python:
  - fullName: float
    name: float
    uid: float
  - fullName: ', '
    name: ', '
  - fullName: '['
    name: '['
  - fullName: 0,1
    name: 0,1
    uid: 0,1
  - fullName: )
    name: )
  uid: float, [0,1)
- fullName: cntk.ops.str, optional
  name: str, optional
  spec.python:
  - fullName: cntk.ops.str
    name: str
    uid: cntk.ops.str
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: cntk.ops.str, optional
- fullName: bool, optional
  name: bool, optional
  spec.python:
  - fullName: bool
    name: bool
    uid: bool
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: bool, optional
- fullName: tuple, default
  name: tuple, default
  spec.python:
  - fullName: tuple
    name: tuple
    uid: tuple
  - fullName: ', '
    name: ', '
  - fullName: default
    name: default
    uid: default
  uid: tuple, default
- fullName: double, default 0.00001
  name: double, 00001
  spec.python:
  - fullName: double
    name: double
    uid: double
  - fullName: ', '
    name: ', '
  - fullName: default 0.00001
    name: '00001'
    uid: default 0.00001
  uid: double, default 0.00001
- fullName: str, optional, keyword only
  name: str, optional, keyword only
  spec.python:
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  - fullName: ', '
    name: ', '
  - fullName: keyword only
    name: keyword only
    uid: keyword only
  uid: str, optional, keyword only
- fullName: default [False,]
  name: default [False,]
  spec.python:
  - fullName: 'default '
    name: 'default '
    uid: 'default '
  - fullName: '['
    name: '['
  - fullName: False,
    name: False,
    uid: False,
  - fullName: ']'
    name: ']'
  uid: default [False,]
- fullName: float, optional
  name: float, optional
  spec.python:
  - fullName: float
    name: float
    uid: float
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: float, optional
- fullName: cntk.axis.Axis, optional, keyword only
  name: Axis, optional, keyword only
  spec.python:
  - fullName: cntk.axis.Axis
    name: Axis
    uid: cntk.axis.Axis
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  - fullName: ', '
    name: ', '
  - fullName: keyword only
    name: keyword only
    uid: keyword only
  uid: cntk.axis.Axis, optional, keyword only
